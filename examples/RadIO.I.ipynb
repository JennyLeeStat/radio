{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with RadIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the first notebook in series of tutorials covering deep learning research of lung cancer using RadIO. Here you will learn about (1) general approach of RadIO when working with dataset of scans and (2) perform basic preprocessing operations (load of data into memory and resize of scans). As you will see in a minute, the (1) will save you the trouble of looping through the dataset that cannot fit into memory. In turn, learning (2) will give you a good idea of how one can build complex preprocessing pipelines using RadIO.\n",
    "\n",
    "In this tutorial you will work with [LUNA16 competition dataset](https://luna16.grand-challenge.org/), consisting of 888 cancer-annotated examples of scans of Computational Tomography (CT-scans). Annotations is simply a csv-table that contains location and diameter of cancerous nodules. In order to follow the tutorial, we advice you to download at least part of this dataset on [this link](https://luna16.grand-challenge.org/download/) (you will need a registration).\n",
    "\n",
    "Alternatively, you can download a small set of scans along with cancer-annotations [here](some-dropbox-link). The archive takes no more than 500 MB and is just enough to get started with RadIO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Working with dataset of scans with ease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very first thing that one should understand about CT-scans is that they are **voluminous**. It is not possible to fit more than a few scans into memory. The only way to work with such large datasets is through an **indexing structure** (think of ...). In RadIO, you can create this structure in two lines of code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note\n",
    "RadIO works with datasets using the *Dataset-framework.* Check [the link](https://github.com/analysiscenter/dataset) to find out more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LUNA_MASK = 'D:/SCANS/v-20161117/*'  # set mask for scans from Luna-dataset here\n",
    "from radio.dataset import FilesIndex\n",
    "luna_index = FilesIndex(path=LUNA_MASK, dirs=True) # ,no_ext=True) # preparing indexing structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RadIO works with scans using *batch-classes* **`CTImagesBatch`** and **`CTImagesMaskedBatch`**, which describe the logic of processing batches of CT-scans (`load` of data from disk, `resize` of scans to different shape). When we combine data processing logic and the index, we obtain the `dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from radio.dataset import Dataset\n",
    "from radio import CTImagesMaskedBatch\n",
    "luna_dataset = Dataset(index=luna_index, batch_class=CTImagesMaskedBatch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..and that's it, all necessary prerequisities are set up. It is time to get your hands on real data-processing operations of RadIO: `load` and `resize`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing with RadIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RadIO-team thinks of preprocessing as of chained sequence of operations, called `actions`. A sequence of actions is called `Pipeline`. Whichever preprocessing you want to do, you should start with setting up a pipeline in **lazy-mode**. That is, you only provide a description of what will happen with data and no real computation is performed.\n",
    "\n",
    "First and foremost, you need to load scans data from disk. Let us set up a short pipeline for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from radio.dataset import Pipeline\n",
    "preprocessing = Pipeline() # initialize empty Pipeline-object\n",
    "preprocessing = preprocessing.load(fmt='raw') # the thing is lazy. No calculation is performed here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did was to assemble a `Pipeline` from one action `load` with arguments `fmt=\"raw\"`. Argument `fmt` specifies the format of data and `raw` stands for **MetaImage-format** Luna-dataset is stored in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real calculation starts only when we pass a dataset through a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pic from Anya goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g., you can generate a batch of 3 scans with loaded data with this code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = (luna_dataset >> preprocessing).next_batch(batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RadIO includes the following actions:\n",
    "* load (data from disk)\n",
    "* resize (change shape of scans to, say, **[128, 256, 256]**)\n",
    "* unify_spacing (reshape scans so that spacings between different scans be the same: say, **[1.0, 1.0, 1.0]** mms)\n",
    "* dump (possibly preprocessed scans-data on disk)\n",
    "* ..and many more\n",
    "\n",
    "Go [here](link-on-preprocessing-page) to see the full list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

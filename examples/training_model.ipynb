{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "sys.path.append('../..')\n",
    "\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import ipywidgets\n",
    "from ipywidgets import interact\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from lung_cancer.dataset import FilesIndex, Dataset, action, model, any_action_failed\n",
    "from lung_cancer.preprocessing import CTImagesBatch, CTImagesMaskedBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lung_cancer.models.metrics import log_loss, accuracy, tpr, fpr, precision, recall\n",
    "from lung_cancer.models.keras_resnet import KerasResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = KerasResNet('keras_resnet')\n",
    "resnet_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomBatch(CTImagesMaskedBatch):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.labels = None\n",
    "    \n",
    "    @model()\n",
    "    def keras_resnet():\n",
    "        return resnet_model\n",
    "    \n",
    "    def visualize(self, component):\n",
    "        size = len(self)\n",
    "        @interact(item=ipywidgets.IntSlider(value=0, min=0, max=size-1), slc=ipywidgets.FloatSlider(0, min=0, max=0.99, step=0.01))\n",
    "        def visualizer(item, slc):\n",
    "            if component == 'nodule':\n",
    "                image = self.get(item, 'images') * self.get(item, 'masks')\n",
    "            else:\n",
    "                image = self.get(item, component)\n",
    "            image_slice = int(slc * image.shape[0])\n",
    "            plt.imshow(image[image_slice, :, :])\n",
    "            plt.show()\n",
    "        return visualizer\n",
    "\n",
    "    @action\n",
    "    def train_on_crop(self, model_name, y_component='labels', dim_ordering='channels_last', **kwargs):\n",
    "        \"\"\" Train model on crops of CT-scans contained in batch.\n",
    "\n",
    "        Args:\n",
    "        - model_name: str, name of classification model;\n",
    "        - y_component: str, name of y component, can be 'masks' or 'labels';\n",
    "        - dim_ordering: str, dimension ordering, can be 'channels_first' or 'channels_last';\n",
    "\n",
    "        Returns:\n",
    "        - self, unchanged CTImagesMaskedBatch;\n",
    "        \"\"\"\n",
    "        super().train_on_crop(model_name, y_component, dim_ordering)\n",
    "        model = self.get_model_by_name(model_name)\n",
    "        x, y_true = self.unpack_data(dim_ordering=dim_ordering, y_component=y_component)\n",
    "        y_pred = model.predict_on_batch(x)\n",
    "        sys.stdout.write(\"Log loss on train: \" + str(log_loss(y_pred, y_true)) + '\\n')\n",
    "        sys.stdout.write(str(pd.DataFrame(np.array([y_pred.ravel(), y_true.ravel()]).T)))\n",
    "        sys.stdout.flush()\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        return self\n",
    "\n",
    "    @action\n",
    "    def test_on_crop_dataset(self, model_name, dataset, batch_size, callbacks=(), test_freq=10):\n",
    "        \"\"\" Test model on data contained in batch. \"\"\"\n",
    "\n",
    "        if not hasattr(dataset, 'metrics'):\n",
    "            dataset.metrics = []\n",
    "        if not hasattr(dataset, 'counter'):\n",
    "            dataset.counter = 0\n",
    "        if dataset.counter % 20 == 0:\n",
    "            model = self.get_model_by_name(model_name)\n",
    "            y_pred_list, y_true_list = [], []\n",
    "            for batch in dataset.gen_batch(batch_size):\n",
    "                batch.load(fmt='blosc').create_labels_by_mask(threshold=10)\n",
    "                x, batch_y_true = batch.unpack_data(dim_ordering='channels_last', y_component='labels')\n",
    "                batch_y_pred = np.asarray(model.predict_on_batch(x))\n",
    "\n",
    "                y_pred_list.append(batch_y_pred.ravel())\n",
    "                y_true_list.append(batch_y_true.ravel())\n",
    "\n",
    "            y_pred = np.concatenate(y_pred_list, axis=0)\n",
    "            y_true = np.concatenate(y_true_list, axis=0)\n",
    "\n",
    "            metrics_values = {m.__name__: m(y_pred, y_true) for m in callbacks}\n",
    "\n",
    "            if not hasattr(dataset, 'metrics'):\n",
    "                dataset.metrics = []\n",
    "            if not hasattr(dataset, 'counter'):\n",
    "                dataset.counter = 0\n",
    "            dataset.metrics.append(metrics_values)\n",
    "            if dataset.counter % test_freq == 0:\n",
    "                print(pd.DataFrame(dataset.metrics))\n",
    "                sys.stdout.flush()\n",
    "                clear_output(wait=True)\n",
    "\n",
    "        dataset.counter += 1\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline for training classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "luna_index = FilesIndex(path='/data/final_nodules_dump/*', dirs=True)\n",
    "luna_dataset = Dataset(luna_index, batch_class=CustomBatch)\n",
    "luna_dataset.cv_split(shares=0.9, shuffle=81)\n",
    "\n",
    "train_pipeline = \\\n",
    "(\n",
    "    luna_dataset.train\n",
    "                .pipeline()\n",
    "                .load(fmt='blosc', src_blosc=['images', 'masks',\n",
    "                                              'origin', 'spacing'])\n",
    "    \n",
    "                .create_labels_by_mask(threshold=10)\n",
    "                .train_on_crop(model_name='keras_resnet',\n",
    "                               y_component='labels',\n",
    "                               dim_ordering='channels_last')\n",
    "\n",
    "                .test_on_crop_dataset('keras_resnet',\n",
    "                                      luna_dataset.test, batch_size=4,\n",
    "                                      callbacks=(log_loss, accuracy),\n",
    "                                      test_freq=20)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run pipeline with batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lung_cancer.dataset.dataset.pipeline.Pipeline at 0x7f2174d9fcc0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pipeline.run(batch_size=16, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline for getting predictions on full scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NODULES_DF = pd.read_csv('/notebooks/data/MRT/luna/CSVFILES/annotations.csv')\n",
    "scans_index = FilesIndex(path= '/notebooks/data/MRT/luna/s*/*.mhd', no_ext=True)\n",
    "scans_dataset = Dataset(scans_index, batch_class=CustomBatch)\n",
    "scans_result = {}\n",
    "\n",
    "scans_pipeline = \\\n",
    "(\n",
    "        scans_dataset.pipeline()\n",
    "                     .load(fmt='raw')\n",
    "                     .normalize_hu()\n",
    "                     .fetch_nodules_info(nodules_df=NODULES_DF)\n",
    "                     .create_mask()\n",
    "                     .unify_spacing(shape=(256, 256, 256), spacing=(1.3, 1.3, 1.3), padding='reflect')\n",
    "                     .predict_on_scan('keras_resnet', y_component='labels', strides=(32, 64, 64))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run pipeline on 4 full scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch = scans_pipeline.next_batch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch.visualize('images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch.visualize('masks')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

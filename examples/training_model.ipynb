{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "sys.path.append('../..')\n",
    "\n",
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from lung_cancer.dataset import FilesIndex, Dataset, action, model, any_action_failed\n",
    "from lung_cancer.preprocessing import CTImagesBatch, CTImagesMaskedBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lung_cancer.models.metrics import log_loss, accuracy, tpr, fpr, precision, recall\n",
    "from lung_cancer.models.keras_resnet import KerasResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "keras_model.py[LINE:24]#INFO     [2017-08-21 17:09:12,395]  Building keras model...\n",
      "keras_model.py[LINE:26]#INFO     [2017-08-21 17:09:16,892]  Keras model was build\n",
      "keras_model.py[LINE:47]#INFO     [2017-08-21 17:09:16,892]  Compiling keras model...\n",
      "keras_model.py[LINE:49]#INFO     [2017-08-21 17:09:16,935]  Model was compiled\n"
     ]
    }
   ],
   "source": [
    "resnet_model = KerasResNet('keras_resnet')\n",
    "resnet_model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBatch(CTImagesMaskedBatch):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.labels = None\n",
    "    \n",
    "    @model()\n",
    "    def keras_resnet():\n",
    "        return resnet_model\n",
    "\n",
    "    @action\n",
    "    def create_labels_by_mask(self, threshold):\n",
    "        self.labels = np.asarray([np.sum(self.get(i, 'masks')) > threshold\n",
    "                                 for i in range(len(self))], dtype=np.float)\n",
    "        return self\n",
    "\n",
    "    def unpack_data(self, y_component, dim_ordering='channels_last', **kwargs):\n",
    "        \"\"\" Unpack data contained in batch for feeding in model.\n",
    "\n",
    "        Args:\n",
    "        - y_component: str, name of y_component to fetch, can be 'masks' or 'labels';\n",
    "        - dim_ordering: str, can be 'channels_last' or 'channels_first';\n",
    "\n",
    "        Returns:\n",
    "        - x, y ndarrays;\n",
    "        \"\"\"\n",
    "        x, y = [], [] if y_component is not None else None\n",
    "        for i in range(len(self)):\n",
    "            x.append(self.get(i, 'images'))\n",
    "            if y_component == 'masks':\n",
    "                y.append(self.get(i, 'masks'))\n",
    "            if y_component == 'labels':\n",
    "                y.append(self.labels[i])\n",
    "        x, y = np.stack(x), np.stack(y)\n",
    "        if dim_ordering == 'channels_last':\n",
    "            x, y = x[..., np.newaxis], y[..., np.newaxis]\n",
    "        elif dim_ordering == 'channels_first':\n",
    "            x = x[:, np.newaxis, ...]\n",
    "            if y_component == 'masks':\n",
    "                y = y[:, np.newaxis, ...]\n",
    "        return x, y\n",
    "\n",
    "    @action\n",
    "    def train_on_crop(self, model_name, y_component='labels', dim_ordering='channels_last', **kwargs):\n",
    "        \"\"\" Train model on crops of CT-scans contained in batch.\n",
    "\n",
    "        Args:\n",
    "        - model_name: str, name of classification model;\n",
    "        - y_component: str, name of y component, can be 'masks' or 'labels';\n",
    "        - dim_ordering: str, dimension ordering, can be 'channels_first' or 'channels_last';\n",
    "\n",
    "        Returns:\n",
    "        - self, unchanged CTImagesMaskedBatch;\n",
    "        \"\"\"\n",
    "        model = self.get_model_by_name(model_name)\n",
    "        x, y_true = self.unpack_data(dim_ordering='channels_last',\n",
    "                                     y_component=y_component, **kwargs)\n",
    "        model.train_on_batch(x, y_true)\n",
    "        \n",
    "        y_pred = model.predict_on_batch(x)\n",
    "        sys.stdout.write(\"Log loss on train: \" + str(log_loss(y_pred, y_true)) + '\\n')\n",
    "        sys.stdout.write(str(pd.DataFrame(np.array([y_pred.ravel(), y_true.ravel()]).T)))\n",
    "        sys.stdout.flush()\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        return self\n",
    "\n",
    "    @action\n",
    "    def predict_on_crop(self, model_name, dst_dict, y_component='labels', dim_ordering='channels_last', **kwargs):\n",
    "        \"\"\" Get predictions of model on crops of CT-scans contained in batch.\n",
    "\n",
    "        Args:\n",
    "        - model_name: str, name of classification model;\n",
    "        - dst_dict: dictionary that will be updated by predictions;\n",
    "\n",
    "        - y_component: str, name of y component, can be 'masks' or 'labels';\n",
    "        - dim_ordering: str, dimension ordering, can be 'channels_first' or 'channels_last';\n",
    "\n",
    "        Returns:\n",
    "        - self, unchanged CTImagesMaskedBatch;\n",
    "        \"\"\"\n",
    "        model = self.get_model_by_name(model_name)\n",
    "        x, _ = self.unpack_data(dim_ordering=dim_ordering,\n",
    "                                y_component=y_component, **kwargs)\n",
    "        predicted_labels = model.predict_on_batch(x)\n",
    "        dst_dict.update(zip(self.indices, predicted_labels))\n",
    "        return self\n",
    "\n",
    "    @action\n",
    "    def test_on_crop_dataset(self, model_name, dataset, batch_size, callbacks=(), test_freq=10):\n",
    "        \"\"\" Test model on data contained in batch. \"\"\"\n",
    "\n",
    "        if not hasattr(dataset, 'metrics'):\n",
    "            dataset.metrics = []\n",
    "        if not hasattr(dataset, 'counter'):\n",
    "            dataset.counter = 0\n",
    "        if dataset.counter % 20 == 0:\n",
    "            model = self.get_model_by_name(model_name)\n",
    "            y_pred_list, y_true_list = [], []\n",
    "            for batch in dataset.gen_batch(batch_size):\n",
    "                batch.load(fmt='blosc').create_labels_by_mask(threshold=10)\n",
    "                x, batch_y_true = batch.unpack_data(dim_ordering='channels_last', y_component='labels')\n",
    "                batch_y_pred = np.asarray(model.predict_on_batch(x))\n",
    "\n",
    "                y_pred_list.append(batch_y_pred.ravel())\n",
    "                y_true_list.append(batch_y_true.ravel())\n",
    "\n",
    "            y_pred = np.concatenate(y_pred_list, axis=0)\n",
    "            y_true = np.concatenate(y_true_list, axis=0)\n",
    "\n",
    "            metrics_values = {m.__name__: m(y_pred, y_true) for m in callbacks}\n",
    "\n",
    "            if not hasattr(dataset, 'metrics'):\n",
    "                dataset.metrics = []\n",
    "            if not hasattr(dataset, 'counter'):\n",
    "                dataset.counter = 0\n",
    "            dataset.metrics.append(metrics_values)\n",
    "            if dataset.counter % test_freq == 0:\n",
    "                print(pd.DataFrame(dataset.metrics))\n",
    "                sys.stdout.flush()\n",
    "                clear_output(wait=True)\n",
    "\n",
    "        dataset.counter += 1\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "luna_index = FilesIndex(path='/home/kirill/ds_bowl/final_nodules_dump/*', dirs=True)\n",
    "luna_dataset = Dataset(luna_index, batch_class=CustomBatch)\n",
    "luna_dataset.cv_split(shares=0.9, shuffle=81)\n",
    "\n",
    "train_pipeline = \\\n",
    "(\n",
    "    luna_dataset.train\n",
    "                .pipeline()\n",
    "                .load(fmt='blosc', src_blosc=['images', 'masks',\n",
    "                                              'origin', 'spacing'])\n",
    "                .create_labels_by_mask(threshold=10)\n",
    "                .train_on_crop('keras_resnet')\n",
    "                .test_on_crop_dataset('keras_resnet',\n",
    "                                      luna_dataset.test, batch_size=4,\n",
    "                                      callbacks=(log_loss, accuracy),\n",
    "                                      test_freq=20)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lung_cancer.dataset.dataset.pipeline.Pipeline at 0x7f2174d9fcc0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pipeline.run(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

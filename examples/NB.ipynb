{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building cancer-detection system with RadIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CT-scans and Lung-cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some imports\n",
    "from ipywidgets import interact\n",
    "from plotting_tools import pil_plot_slices\n",
    "from example import load_example\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CT-scans are 3d-arrays of data. Cancer in lungs is represented in *pulmonary nodules*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21a5557fd9ad4d9798e82aa7ab60ff18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.49, description='height', max=0.99, step=0.01), Output()), _dom_clasâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(height)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot the scan and corresponding mask\n",
    "PATH_TO_SAMPLE = '/home/alexander/Work/Temp/unrarred/needed/other/_demo_data/scans_sample/'\n",
    "bch = load_example(path=os.path.join(PATH_TO_SAMPLE,\n",
    "                                     '1.3.6.1.4.1.14519.5.2.1.6279.6001.621916089407825046337959219998'))\n",
    "num_item = 0\n",
    "interact(lambda height: pil_plot_slices(height, bch.get(num_item, 'images'), bch.get(num_item, 'masks')),\n",
    "         height=(0, 0.99, 0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dealing with imperfect annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building detection system-workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Dataset` and `Pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CT-scans are voluminous. It is not possible to store all scans from the dataset in memory at once. In order to work with the dataset of scans, we create `Dataset`: an *indexing strructure*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from radio.dataset import FilesIndex, Dataset, Pipeline\n",
    "from radio import CTImagesMaskedBatch\n",
    "\n",
    "luna_index = FilesIndex(path=os.path.join(PATH_TO_SAMPLE, '*'),\n",
    "                        dirs=True)                                    # preparing indexing structure\n",
    "lunaset = Dataset(index=luna_index, batch_class=CTImagesMaskedBatch)  # Dataset: logic + indexing structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1.3.6.1.4.1.14519.5.2.1.6279.6001.240969450540588211676803094518',\n",
       "       '1.3.6.1.4.1.14519.5.2.1.6279.6001.837810280808122125183730411210',\n",
       "       '1.3.6.1.4.1.14519.5.2.1.6279.6001.197063290812663596858124411210'],\n",
       "      dtype='<U136')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luna_index.indices[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/alexander/Work/Temp/unrarred/needed/other/_demo_data/scans_sample/1.3.6.1.4.1.14519.5.2.1.6279.6001.240969450540588211676803094518'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luna_index.get_fullpath(luna_index.indices[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data-processing workflows are called `pipelines`, which represent sequences(plans) of actions on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not run it, it's fake!\n",
    "some_pipeline = (Pipeline()\n",
    "                 .load()\n",
    "                 .preprocess_somehow()\n",
    "                 .do_something_else()\n",
    "                 ....)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform some real computation we need to pass a batch through a `pipeline`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not run it, it's fake!\n",
    "batch = (dataset >> some_pipeline).next_batch(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first: load the data. `RadIO` uses asychronous loading with `aiofiles`. Should be fast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = (Pipeline()\n",
    "                 .load(fmt='blosc', components=['images', 'spacing', 'origin']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luna-dataset provides cancer-annotations for targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNO_PATH = '/home/alexander/Work/Data/CSVFILES/annotations.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seriesuid</th>\n",
       "      <th>coordX</th>\n",
       "      <th>coordY</th>\n",
       "      <th>coordZ</th>\n",
       "      <th>diameter_mm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n",
       "      <td>-128.699421</td>\n",
       "      <td>-175.319272</td>\n",
       "      <td>-298.387506</td>\n",
       "      <td>5.651471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...</td>\n",
       "      <td>103.783651</td>\n",
       "      <td>-211.925149</td>\n",
       "      <td>-227.121250</td>\n",
       "      <td>4.224708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           seriesuid      coordX      coordY  \\\n",
       "0  1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222... -128.699421 -175.319272   \n",
       "1  1.3.6.1.4.1.14519.5.2.1.6279.6001.100225287222...  103.783651 -211.925149   \n",
       "\n",
       "       coordZ  diameter_mm  \n",
       "0 -298.387506     5.651471  \n",
       "1 -227.121250     4.224708  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "nodules_df = pd.read_csv(ANNO_PATH)\n",
    "nodules_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make use of it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing += (Pipeline()\n",
    "                  .fetch_nodules_info(nodules_df)\n",
    "                  .create_mask())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize data-range to [0, 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing += (Pipeline()\n",
    "                  .normalize_hu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps you need to `dump` preprocessed scans and get back to them later?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing += (Pipeline()\n",
    "                  .dump(fmt='blosc', dst='/home/alexander/Work/Data/Temp_dump/',\n",
    "                        components=['images', 'masks', 'spacing', 'origin'], i8_encoding_mode='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = (lunaset >> preprocessing).next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../tutorials/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import show_slices\n",
    "import numpy as np\n",
    "ixs = np.array(['1.3.6.1.4.1.14519.5.2.1.6279.6001.768276876111112560631432843476',\n",
    "                '1.3.6.1.4.1.14519.5.2.1.6279.6001.621916089407825046337959219998'])\n",
    "\n",
    "\n",
    "two_scans_dataset = Dataset(index=luna_index.create_subset(ixs), batch_class=CTImagesMaskedBatch)\n",
    "batch = (two_scans_dataset >> preprocessing).next_batch(2, shuffle=False)   # pass a batch through the workflow\n",
    "show_slices(batch, scan_indices=[0, 1], ns_slice=[211, 67], grid=True, clims=(0, 255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see that the lungs are larger on the left scan. This can be explained by a big difference in scale (represented by a grid). This can be a source of uncontrollable variation in the training dataset. In order to make scans more isotropic, we add action `unify_spacing` to our preprocessing workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = (256, 256, 256)\n",
    "SPACING = (1.7, 1., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing += (Pipeline()\n",
    "                  .unify_spacing(spacing=SPACING, shape=SHAPE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now pass a batch through the workflow and see the difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = (two_scans_dataset >> preprocessing).next_batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_slices(batch, scan_indices=[0, 1], ns_slice=[124, 124], grid=True, clims=(0, 255))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us add some augmentation actions to the workflow. To begin with, let's *controllably* introduce variation into the scale by randomly zooming in/zooming out on scans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing_options = [(1.7, 0.5, 0.5), (1.7, 1.0, 1.0), (1.7, 1.5, 1.5), (1.7, 2.0, 2.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we define spacing randomizer, a function that randomly fetches spacing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing_randomizer = lambda *args: spacing_options[np.random.choice(range(len(spacing_options)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from radio.dataset import F                                          # see below the explanation\n",
    "augmentation = (Pipeline()                                           # empty workflow\n",
    "                .load(fmt='raw')                                     # load scans\n",
    "                .unify_spacing(spacing=F(spacing_randomizer), shape=(256, 256, 256)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add some rotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation += (Pipeline()\n",
    "                 .rotate(random=True, angle=30, components=['images', 'masks']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIPs: a way to reduce 3d-problem to a 2d-one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "xips = batch.xip('images', mode='max', depth=7, stride=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "lxip = int(len(xips) / len(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cadf1efd49ec45e08b89808c5b27bb34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.495, description='height', max=0.99, step=0.005), Output()), _dom_clâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(height)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(lambda height: pil_plot_slices(height, batch.get(num_item, 'images'), xips[0:lxip, :, :, 0],\n",
    "                                        batch.get(num_item, 'masks')),\n",
    "         height=(0, 0.99, 0.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from radio.dataset import B, V, F\n",
    "from radio.dataset.models.tf import TFModel\n",
    "\n",
    "model_path = 'unet/e_6_3c_unet/models/logloss/'\n",
    "config = dict(load=dict(path=model_path),\n",
    "              session=dict(config=tf.ConfigProto(allow_soft_placement=True)))\n",
    "\n",
    "\n",
    "SHAPE = (128, 256, 256)\n",
    "SPACING = (1.7, 1, 1)\n",
    "XIP_PARAMS = dict(mode='max', depth=6, stride=2, channels=3)\n",
    "\n",
    "ppl_predict_scan = (Pipeline()\n",
    "                    .init_model('static', TFModel, 'xipnet', config)\n",
    "                    .load(fmt='blosc', components=['images', 'spacing', 'origin', 'masks'])\n",
    "                    .fetch_nodules_from_mask()\n",
    "                    .init_variables(['predictions', 'nodules_true', 'nodules_predicted'])\n",
    "                    .fetch_nodules_from_mask()\n",
    "                    .update_variable('nodules_true', B('nodules'))\n",
    "                    .predict_model('xipnet', save_to=V('predictions'),\n",
    "                                   feed_dict=dict(images=F(CTIMB.xip, component='images', **XIP_PARAMS)))\n",
    "                    .call(CTIMB.unxip, xip=V('predictions'), squeeze=True, **XIP_PARAMS,\n",
    "                          component='masks')\n",
    "                    .fetch_nodules_from_mask()\n",
    "                    .update_variable('nodules_predicted', B('nodules')) << lunaset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

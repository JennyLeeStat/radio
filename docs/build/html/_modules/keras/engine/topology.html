
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>keras.engine.topology &#8212; RadIO 0.1.0 documentation</title>
    <link rel="stylesheet" href="../../../_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../',
        VERSION:     '0.1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
  </head>
  <body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">RadIO 0.1.0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../index.html" accesskey="U">Module code</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for keras.engine.topology</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">print_function</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">absolute_import</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">yaml</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">six.moves</span> <span class="k">import</span> <span class="nb">zip</span>

<span class="kn">from</span> <span class="nn">..</span> <span class="k">import</span> <span class="n">backend</span> <span class="k">as</span> <span class="n">K</span>
<span class="kn">from</span> <span class="nn">..</span> <span class="k">import</span> <span class="n">initializers</span>
<span class="kn">from</span> <span class="nn">..utils.io_utils</span> <span class="k">import</span> <span class="n">ask_to_proceed_with_overwrite</span>
<span class="kn">from</span> <span class="nn">..utils.layer_utils</span> <span class="k">import</span> <span class="n">print_summary</span> <span class="k">as</span> <span class="n">print_layer_summary</span>
<span class="kn">from</span> <span class="nn">..utils.generic_utils</span> <span class="k">import</span> <span class="n">has_arg</span>
<span class="kn">from</span> <span class="nn">..utils</span> <span class="k">import</span> <span class="n">conv_utils</span>
<span class="kn">from</span> <span class="nn">..legacy</span> <span class="k">import</span> <span class="n">interfaces</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">h5py</span>
<span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
    <span class="n">h5py</span> <span class="o">=</span> <span class="kc">None</span>


<span class="k">class</span> <span class="nc">InputSpec</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Specifies the ndim, dtype and shape of every input to a layer.</span>

<span class="sd">    Every layer should expose (if appropriate) an `input_spec` attribute:</span>
<span class="sd">    a list of instances of InputSpec (one per input tensor).</span>

<span class="sd">    A None entry in a shape is compatible with any dimension,</span>
<span class="sd">    a None shape is compatible with any shape.</span>

<span class="sd">    # Arguments</span>
<span class="sd">        dtype: Expected datatype of the input.</span>
<span class="sd">        shape: Shape tuple, expected shape of the input</span>
<span class="sd">            (may include None for unchecked axes).</span>
<span class="sd">        ndim: Integer, expected rank of the input.</span>
<span class="sd">        max_ndim: Integer, maximum rank of the input.</span>
<span class="sd">        min_ndim: Integer, minimum rank of the input.</span>
<span class="sd">        axes: Dictionary mapping integer axes to</span>
<span class="sd">            a specific dimension value.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">ndim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">max_ndim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">min_ndim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">axes</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">shape</span> <span class="o">=</span> <span class="n">shape</span>
        <span class="k">if</span> <span class="n">shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ndim</span> <span class="o">=</span> <span class="n">ndim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_ndim</span> <span class="o">=</span> <span class="n">max_ndim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_ndim</span> <span class="o">=</span> <span class="n">min_ndim</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">axes</span> <span class="o">=</span> <span class="n">axes</span> <span class="ow">or</span> <span class="p">{}</span>


<span class="k">class</span> <span class="nc">Node</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A `Node` describes the connectivity between two layers.</span>

<span class="sd">    Each time a layer is connected to some new input,</span>
<span class="sd">    a node is added to `layer.inbound_nodes`.</span>
<span class="sd">    Each time the output of a layer is used by another layer,</span>
<span class="sd">    a node is added to `layer.outbound_nodes`.</span>

<span class="sd">    # Arguments</span>
<span class="sd">        outbound_layer: the layer that takes</span>
<span class="sd">            `input_tensors` and turns them into `output_tensors`</span>
<span class="sd">            (the node gets created when the `call`</span>
<span class="sd">            method of the layer was called).</span>
<span class="sd">        inbound_layers: a list of layers, the same length as `input_tensors`,</span>
<span class="sd">            the layers from where `input_tensors` originate.</span>
<span class="sd">        node_indices: a list of integers, the same length as `inbound_layers`.</span>
<span class="sd">            `node_indices[i]` is the origin node of `input_tensors[i]`</span>
<span class="sd">            (necessary since each inbound layer might have several nodes,</span>
<span class="sd">            e.g. if the layer is being shared with a different data stream).</span>
<span class="sd">        tensor_indices: a list of integers,</span>
<span class="sd">            the same length as `inbound_layers`.</span>
<span class="sd">            `tensor_indices[i]` is the index of `input_tensors[i]` within the</span>
<span class="sd">            output of the inbound layer</span>
<span class="sd">            (necessary since each inbound layer might</span>
<span class="sd">            have multiple tensor outputs, with each one being</span>
<span class="sd">            independently manipulable).</span>
<span class="sd">        input_tensors: list of input tensors.</span>
<span class="sd">        output_tensors: list of output tensors.</span>
<span class="sd">        input_masks: list of input masks (a mask can be a tensor, or None).</span>
<span class="sd">        output_masks: list of output masks (a mask can be a tensor, or None).</span>
<span class="sd">        input_shapes: list of input shape tuples.</span>
<span class="sd">        output_shapes: list of output shape tuples.</span>
<span class="sd">        arguments: dictionary of keyword arguments that were passed to the</span>
<span class="sd">            `call` method of the layer at the call that created the node.</span>

<span class="sd">    `node_indices` and `tensor_indices` are basically fine-grained coordinates</span>
<span class="sd">    describing the origin of the `input_tensors`, verifying the following:</span>

<span class="sd">    `input_tensors[i] == inbound_layers[i].inbound_nodes[node_indices[i]].output_tensors[tensor_indices[i]]`</span>

<span class="sd">    A node from layer A to layer B is added to:</span>
<span class="sd">        A.outbound_nodes</span>
<span class="sd">        B.inbound_nodes</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outbound_layer</span><span class="p">,</span>
                 <span class="n">inbound_layers</span><span class="p">,</span> <span class="n">node_indices</span><span class="p">,</span> <span class="n">tensor_indices</span><span class="p">,</span>
                 <span class="n">input_tensors</span><span class="p">,</span> <span class="n">output_tensors</span><span class="p">,</span>
                 <span class="n">input_masks</span><span class="p">,</span> <span class="n">output_masks</span><span class="p">,</span>
                 <span class="n">input_shapes</span><span class="p">,</span> <span class="n">output_shapes</span><span class="p">,</span>
                 <span class="n">arguments</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Layer instance (NOT a list).</span>
        <span class="c1"># this is the layer that takes a list of input tensors</span>
        <span class="c1"># and turns them into a list of output tensors.</span>
        <span class="c1"># the current node will be added to</span>
        <span class="c1"># the inbound_nodes of outbound_layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outbound_layer</span> <span class="o">=</span> <span class="n">outbound_layer</span>

        <span class="c1"># The following 3 properties describe where</span>
        <span class="c1"># the input tensors come from: which layers,</span>
        <span class="c1"># and for each layer, which node and which</span>
        <span class="c1"># tensor output of each node.</span>

        <span class="c1"># List of layer instances.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inbound_layers</span> <span class="o">=</span> <span class="n">inbound_layers</span>
        <span class="c1"># List of integers, 1:1 mapping with inbound_layers.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">node_indices</span> <span class="o">=</span> <span class="n">node_indices</span>
        <span class="c1"># List of integers, 1:1 mapping with inbound_layers.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tensor_indices</span> <span class="o">=</span> <span class="n">tensor_indices</span>

        <span class="c1"># Following 2 properties:</span>
        <span class="c1"># tensor inputs and outputs of outbound_layer.</span>

        <span class="c1"># List of tensors. 1:1 mapping with inbound_layers.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_tensors</span> <span class="o">=</span> <span class="n">input_tensors</span>
        <span class="c1"># List of tensors, created by outbound_layer.call().</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_tensors</span> <span class="o">=</span> <span class="n">output_tensors</span>

        <span class="c1"># Following 2 properties: input and output masks.</span>
        <span class="c1"># List of tensors, 1:1 mapping with input_tensor.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_masks</span> <span class="o">=</span> <span class="n">input_masks</span>
        <span class="c1"># List of tensors, created by outbound_layer.compute_mask().</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_masks</span> <span class="o">=</span> <span class="n">output_masks</span>

        <span class="c1"># Following 2 properties: input and output shapes.</span>

        <span class="c1"># List of shape tuples, shapes of input_tensors.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_shapes</span> <span class="o">=</span> <span class="n">input_shapes</span>
        <span class="c1"># List of shape tuples, shapes of output_tensors.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_shapes</span> <span class="o">=</span> <span class="n">output_shapes</span>

        <span class="c1"># Optional keyword arguments to layer&#39;s `call`.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">arguments</span> <span class="o">=</span> <span class="n">arguments</span>

        <span class="c1"># Add nodes to all layers involved.</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">inbound_layers</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">layer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">layer</span><span class="o">.</span><span class="n">outbound_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">outbound_layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">inbound_names</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inbound_layers</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">layer</span><span class="p">:</span>
                <span class="n">inbound_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">inbound_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;outbound_layer&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">outbound_layer</span><span class="o">.</span><span class="n">name</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">outbound_layer</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                <span class="s1">&#39;inbound_layers&#39;</span><span class="p">:</span> <span class="n">inbound_names</span><span class="p">,</span>
                <span class="s1">&#39;node_indices&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_indices</span><span class="p">,</span>
                <span class="s1">&#39;tensor_indices&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tensor_indices</span><span class="p">}</span>


<span class="k">class</span> <span class="nc">Layer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Abstract base layer class.</span>

<span class="sd">    # Properties</span>
<span class="sd">        name: String, must be unique within a model.</span>
<span class="sd">        input_spec: List of InputSpec class instances</span>
<span class="sd">            each entry describes one required input:</span>
<span class="sd">                - ndim</span>
<span class="sd">                - dtype</span>
<span class="sd">            A layer with `n` input tensors must have</span>
<span class="sd">            an `input_spec` of length `n`.</span>
<span class="sd">        trainable: Boolean, whether the layer weights</span>
<span class="sd">            will be updated during training.</span>
<span class="sd">        uses_learning_phase: Whether any operation</span>
<span class="sd">            of the layer uses `K.in_training_phase()`</span>
<span class="sd">            or `K.in_test_phase()`.</span>
<span class="sd">        input_shape: Shape tuple. Provided for convenience,</span>
<span class="sd">            but note that there may be cases in which this</span>
<span class="sd">            attribute is ill-defined (e.g. a shared layer</span>
<span class="sd">            with multiple input shapes), in which case</span>
<span class="sd">            requesting `input_shape` will raise an Exception.</span>
<span class="sd">            Prefer using `layer.get_input_shape_for(input_shape)`,</span>
<span class="sd">            or `layer.get_input_shape_at(node_index)`.</span>
<span class="sd">        output_shape: Shape tuple. See above.</span>
<span class="sd">        inbound_nodes: List of nodes.</span>
<span class="sd">        outbound_nodes: List of nodes.</span>
<span class="sd">        input, output: Input/output tensor(s). Note that if the layer is used</span>
<span class="sd">            more than once (shared layer), this is ill-defined</span>
<span class="sd">            and will raise an exception. In such cases, use</span>
<span class="sd">            `layer.get_input_at(node_index)`.</span>
<span class="sd">        input_mask, output_mask: Same as above, for masks.</span>
<span class="sd">        trainable_weights: List of variables.</span>
<span class="sd">        non_trainable_weights: List of variables.</span>
<span class="sd">        weights: The concatenation of the lists trainable_weights and</span>
<span class="sd">            non_trainable_weights (in this order).</span>

<span class="sd">    # Methods</span>
<span class="sd">        call(x, mask=None): Where the layer&#39;s logic lives.</span>
<span class="sd">        __call__(x, mask=None): Wrapper around the layer logic (`call`).</span>
<span class="sd">            If x is a Keras tensor:</span>
<span class="sd">                - Connect current layer with last layer from tensor:</span>
<span class="sd">                    `self._add_inbound_node(last_layer)`</span>
<span class="sd">                - Add layer to tensor history</span>
<span class="sd">            If layer is not built:</span>
<span class="sd">                - Build from x._keras_shape</span>
<span class="sd">        get_weights()</span>
<span class="sd">        set_weights(weights)</span>
<span class="sd">        get_config()</span>
<span class="sd">        count_params()</span>
<span class="sd">        compute_output_shape(input_shape)</span>
<span class="sd">        compute_mask(x, mask)</span>
<span class="sd">        get_input_at(node_index)</span>
<span class="sd">        get_output_at(node_index)</span>
<span class="sd">        get_input_shape_at(node_index)</span>
<span class="sd">        get_output_shape_at(node_index)</span>
<span class="sd">        get_input_mask_at(node_index)</span>
<span class="sd">        get_output_mask_at(node_index)</span>

<span class="sd">    # Class Methods</span>
<span class="sd">        from_config(config)</span>

<span class="sd">    # Internal methods:</span>
<span class="sd">        build(input_shape)</span>
<span class="sd">        _add_inbound_node(layer, index=0)</span>
<span class="sd">        assert_input_compatibility()</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_spec</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">supports_masking</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># These properties will be set upon call of self.build()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_trainable_weights</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_non_trainable_weights</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_updates</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_per_input_losses</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_per_input_updates</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_built</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># These lists will be filled via successive calls</span>
        <span class="c1"># to self._add_inbound_node().</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inbound_nodes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outbound_nodes</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># These properties should be set by the user via keyword arguments.</span>
        <span class="c1"># note that &#39;dtype&#39;, &#39;input_shape&#39; and &#39;batch_input_shape&#39;</span>
        <span class="c1"># are only applicable to input layers: do not pass these keywords</span>
        <span class="c1"># to non-input layers.</span>
        <span class="n">allowed_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;input_shape&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;batch_input_shape&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;batch_size&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;dtype&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;name&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;trainable&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;weights&#39;</span><span class="p">,</span>
                          <span class="s1">&#39;input_dtype&#39;</span><span class="p">,</span>  <span class="c1"># legacy</span>
                          <span class="p">}</span>
        <span class="k">for</span> <span class="n">kwarg</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">kwarg</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">allowed_kwargs</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Keyword argument not understood:&#39;</span><span class="p">,</span> <span class="n">kwarg</span><span class="p">)</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;name&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">name</span><span class="p">:</span>
            <span class="n">prefix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">_to_snake_case</span><span class="p">(</span><span class="n">prefix</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">get_uid</span><span class="p">(</span><span class="n">prefix</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;trainable&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="s1">&#39;input_shape&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span> <span class="ow">or</span> <span class="s1">&#39;batch_input_shape&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="c1"># In this case we will later create an input layer</span>
            <span class="c1"># to insert before the current layer</span>
            <span class="k">if</span> <span class="s1">&#39;batch_input_shape&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="n">batch_input_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;batch_input_shape&#39;</span><span class="p">])</span>
            <span class="k">elif</span> <span class="s1">&#39;input_shape&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                <span class="k">if</span> <span class="s1">&#39;batch_size&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                    <span class="n">batch_size</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;batch_size&#39;</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">batch_size</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="n">batch_input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;input_shape&#39;</span><span class="p">])</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_input_shape</span> <span class="o">=</span> <span class="n">batch_input_shape</span>

            <span class="c1"># Set dtype.</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;dtype&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;input_dtype&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">floatx</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>

        <span class="k">if</span> <span class="s1">&#39;weights&#39;</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_initial_weights</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;weights&#39;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_initial_weights</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_node_key</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">node_index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Converts a layer and its index to a unique (immutable type) name.</span>
<span class="sd">        This function is used internally with `self.container_nodes`.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            layer: The layer.</span>
<span class="sd">            node_index: The layer&#39;s position (e.g. via enumerate) in a list of</span>
<span class="sd">                nodes.</span>

<span class="sd">        # Returns</span>
<span class="sd">            The unique name.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;_ib-&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">losses</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_losses</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">updates</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_updates</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">built</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_built</span>

    <span class="nd">@built</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">built</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_built</span> <span class="o">=</span> <span class="n">value</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">trainable_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">trainable</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;trainable&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">trainable</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trainable_weights</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>

    <span class="nd">@trainable_weights</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">trainable_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_trainable_weights</span> <span class="o">=</span> <span class="n">weights</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">non_trainable_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">trainable</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;trainable&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">trainable</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_trainable_weights</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_trainable_weights</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_non_trainable_weights</span>

    <span class="nd">@non_trainable_weights</span><span class="o">.</span><span class="n">setter</span>
    <span class="k">def</span> <span class="nf">non_trainable_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_non_trainable_weights</span> <span class="o">=</span> <span class="n">weights</span>

    <span class="nd">@interfaces</span><span class="o">.</span><span class="n">legacy_add_weight_support</span>
    <span class="k">def</span> <span class="nf">add_weight</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                   <span class="n">name</span><span class="p">,</span>
                   <span class="n">shape</span><span class="p">,</span>
                   <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                   <span class="n">initializer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                   <span class="n">regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                   <span class="n">trainable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                   <span class="n">constraint</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Adds a weight variable to the layer.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            name: String, the name for the weight variable.</span>
<span class="sd">            shape: The shape tuple of the weight.</span>
<span class="sd">            dtype: The dtype of the weight.</span>
<span class="sd">            initializer: An Initializer instance (callable).</span>
<span class="sd">            regularizer: An optional Regularizer instance.</span>
<span class="sd">            trainable: A boolean, whether the weight should</span>
<span class="sd">                be trained via backprop or not (assuming</span>
<span class="sd">                that the layer itself is also trainable).</span>
<span class="sd">            constraint: An optional Constraint instance.</span>

<span class="sd">        # Returns</span>
<span class="sd">            The created weight variable.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">initializer</span> <span class="o">=</span> <span class="n">initializers</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">initializer</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dtype</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">dtype</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">floatx</span><span class="p">()</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">variable</span><span class="p">(</span><span class="n">initializer</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span>
                            <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
                            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
                            <span class="n">constraint</span><span class="o">=</span><span class="n">constraint</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">regularizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="n">regularizer</span><span class="p">(</span><span class="n">weight</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">trainable</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_trainable_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_non_trainable_weights</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">weight</span>

    <span class="k">def</span> <span class="nf">assert_input_compatibility</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Checks compatibility between the layer and provided inputs.</span>

<span class="sd">        This checks that the tensor(s) `input`</span>
<span class="sd">        verify the input assumptions of the layer</span>
<span class="sd">        (if any). If not, exceptions are raised.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            inputs: input tensor or list of input tensors.</span>

<span class="sd">        # Raises</span>
<span class="sd">            ValueError: in case of mismatch between</span>
<span class="sd">                the provided inputs and the expectations of the layer.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">K</span><span class="o">.</span><span class="n">is_keras_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Layer &#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39; was called with &#39;</span>
                                 <span class="s1">&#39;an input that isn</span><span class="se">\&#39;</span><span class="s1">t a symbolic tensor. &#39;</span>
                                 <span class="s1">&#39;Received type: &#39;</span> <span class="o">+</span>
                                 <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="o">+</span> <span class="s1">&#39;. Full input: &#39;</span> <span class="o">+</span>
                                 <span class="nb">str</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;. All inputs to the layer &#39;</span>
                                 <span class="s1">&#39;should be tensors.&#39;</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_spec</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_spec</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="n">input_spec</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_spec</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">input_spec</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_spec</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_spec</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Layer &#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39; expects &#39;</span> <span class="o">+</span>
                             <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_spec</span><span class="p">))</span> <span class="o">+</span> <span class="s1">&#39; inputs, &#39;</span>
                             <span class="s1">&#39;but it received &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span> <span class="o">+</span>
                             <span class="s1">&#39; input tensors. Input received: &#39;</span> <span class="o">+</span>
                             <span class="nb">str</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">input_index</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">spec</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">input_spec</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="c1"># Check ndim.</span>
            <span class="k">if</span> <span class="n">spec</span><span class="o">.</span><span class="n">ndim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">K</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">!=</span> <span class="n">spec</span><span class="o">.</span><span class="n">ndim</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Input &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">input_index</span><span class="p">)</span> <span class="o">+</span>
                                     <span class="s1">&#39; is incompatible with layer &#39;</span> <span class="o">+</span>
                                     <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;: expected ndim=&#39;</span> <span class="o">+</span>
                                     <span class="nb">str</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;, found ndim=&#39;</span> <span class="o">+</span>
                                     <span class="nb">str</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
            <span class="k">if</span> <span class="n">spec</span><span class="o">.</span><span class="n">max_ndim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">ndim</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">ndim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ndim</span> <span class="o">&gt;</span> <span class="n">spec</span><span class="o">.</span><span class="n">max_ndim</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Input &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">input_index</span><span class="p">)</span> <span class="o">+</span>
                                     <span class="s1">&#39; is incompatible with layer &#39;</span> <span class="o">+</span>
                                     <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;: expected max_ndim=&#39;</span> <span class="o">+</span>
                                     <span class="nb">str</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">max_ndim</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;, found ndim=&#39;</span> <span class="o">+</span>
                                     <span class="nb">str</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
            <span class="k">if</span> <span class="n">spec</span><span class="o">.</span><span class="n">min_ndim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">ndim</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">ndim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ndim</span> <span class="o">&lt;</span> <span class="n">spec</span><span class="o">.</span><span class="n">min_ndim</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Input &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">input_index</span><span class="p">)</span> <span class="o">+</span>
                                     <span class="s1">&#39; is incompatible with layer &#39;</span> <span class="o">+</span>
                                     <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;: expected min_ndim=&#39;</span> <span class="o">+</span>
                                     <span class="nb">str</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">min_ndim</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;, found ndim=&#39;</span> <span class="o">+</span>
                                     <span class="nb">str</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
            <span class="c1"># Check dtype.</span>
            <span class="k">if</span> <span class="n">spec</span><span class="o">.</span><span class="n">dtype</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">K</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">!=</span> <span class="n">spec</span><span class="o">.</span><span class="n">dtype</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Input &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">input_index</span><span class="p">)</span> <span class="o">+</span>
                                     <span class="s1">&#39; is incompatible with layer &#39;</span> <span class="o">+</span>
                                     <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;: expected dtype=&#39;</span> <span class="o">+</span>
                                     <span class="nb">str</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;, found dtype=&#39;</span> <span class="o">+</span>
                                     <span class="nb">str</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
            <span class="c1"># Check specific shape axes.</span>
            <span class="k">if</span> <span class="n">spec</span><span class="o">.</span><span class="n">axes</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">x_shape</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                    <span class="n">x_shape</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">if</span> <span class="n">x_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">axis</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">spec</span><span class="o">.</span><span class="n">axes</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                        <span class="k">if</span> <span class="n">value</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">x_shape</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">axis</span><span class="p">)]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">{</span><span class="n">value</span><span class="p">,</span> <span class="kc">None</span><span class="p">}:</span>
                            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Input &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">input_index</span><span class="p">)</span> <span class="o">+</span>
                                             <span class="s1">&#39; is incompatible with layer &#39;</span> <span class="o">+</span>
                                             <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;: expected axis &#39;</span> <span class="o">+</span>
                                             <span class="nb">str</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39; of input shape to have &#39;</span>
                                             <span class="s1">&#39;value &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">+</span>
                                             <span class="s1">&#39; but got shape &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x_shape</span><span class="p">))</span>
            <span class="c1"># Check shape.</span>
            <span class="k">if</span> <span class="n">spec</span><span class="o">.</span><span class="n">shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">x_shape</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                    <span class="n">x_shape</span> <span class="o">=</span> <span class="kc">None</span>
                <span class="k">if</span> <span class="n">x_shape</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">spec_dim</span><span class="p">,</span> <span class="n">dim</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">x_shape</span><span class="p">):</span>
                        <span class="k">if</span> <span class="n">spec_dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">dim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="k">if</span> <span class="n">spec_dim</span> <span class="o">!=</span> <span class="n">dim</span><span class="p">:</span>
                                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                                    <span class="s1">&#39;Input &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">input_index</span><span class="p">)</span> <span class="o">+</span>
                                    <span class="s1">&#39; is incompatible with layer &#39;</span> <span class="o">+</span>
                                    <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;: expected shape=&#39;</span> <span class="o">+</span>
                                    <span class="nb">str</span><span class="p">(</span><span class="n">spec</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;, found shape=&#39;</span> <span class="o">+</span>
                                    <span class="nb">str</span><span class="p">(</span><span class="n">x_shape</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;This is where the layer&#39;s logic lives.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            inputs: Input tensor, or list/tuple of input tensors.</span>
<span class="sd">            **kwargs: Additional keyword arguments.</span>

<span class="sd">        # Returns</span>
<span class="sd">            A tensor or list/tuple of tensors.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">inputs</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Wrapper around self.call(), for handling internal references.</span>

<span class="sd">        If a Keras tensor is passed:</span>
<span class="sd">            - We call self._add_inbound_node().</span>
<span class="sd">            - If necessary, we `build` the layer to match</span>
<span class="sd">                the _keras_shape of the input(s).</span>
<span class="sd">            - We update the _keras_shape of every input tensor with</span>
<span class="sd">                its new shape (obtained via self.compute_output_shape).</span>
<span class="sd">                This is done as part of _add_inbound_node().</span>
<span class="sd">            - We update the _keras_history of the output tensor(s)</span>
<span class="sd">                with the current layer.</span>
<span class="sd">                This is done as part of _add_inbound_node().</span>

<span class="sd">        # Arguments</span>
<span class="sd">            inputs: Can be a tensor or list/tuple of tensors.</span>
<span class="sd">            **kwargs: Additional keyword arguments to be passed to `call()`.</span>

<span class="sd">        # Returns</span>
<span class="sd">            Output of the layer&#39;s `call` method.</span>

<span class="sd">        # Raises</span>
<span class="sd">            ValueError: in case the layer is missing shape information</span>
<span class="sd">                for its `build` call.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="p">[:]</span>
        <span class="k">with</span> <span class="n">K</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
            <span class="c1"># Handle laying building (weight creating, input spec locking).</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">built</span><span class="p">:</span>
                <span class="c1"># Raise exceptions in case the input is not compatible</span>
                <span class="c1"># with the input_spec specified in the layer constructor.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">assert_input_compatibility</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

                <span class="c1"># Collect input shapes to build layer.</span>
                <span class="n">input_shapes</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">x_elem</span> <span class="ow">in</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">inputs</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x_elem</span><span class="p">,</span> <span class="s1">&#39;_keras_shape&#39;</span><span class="p">):</span>
                        <span class="n">input_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x_elem</span><span class="o">.</span><span class="n">_keras_shape</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="s1">&#39;int_shape&#39;</span><span class="p">):</span>
                        <span class="n">input_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">x_elem</span><span class="p">))</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;You tried to call layer &quot;&#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span>
                                         <span class="s1">&#39;&quot;. This layer has no information&#39;</span>
                                         <span class="s1">&#39; about its expected input shape, &#39;</span>
                                         <span class="s1">&#39;and thus cannot be built. &#39;</span>
                                         <span class="s1">&#39;You can build it manually via: &#39;</span>
                                         <span class="s1">&#39;`layer.build(batch_input_shape)`&#39;</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shapes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">input_shapes</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">built</span> <span class="o">=</span> <span class="kc">True</span>

                <span class="c1"># Load weights that were specified at layer instantiation.</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_initial_weights</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_initial_weights</span><span class="p">)</span>

            <span class="c1"># Raise exceptions in case the input is not compatible</span>
            <span class="c1"># with the input_spec set at build time.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">assert_input_compatibility</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

            <span class="c1"># Handle mask propagation.</span>
            <span class="n">previous_mask</span> <span class="o">=</span> <span class="n">_collect_previous_mask</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">user_kwargs</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">_is_all_none</span><span class="p">(</span><span class="n">previous_mask</span><span class="p">):</span>
                <span class="c1"># The previous layer generated a mask.</span>
                <span class="k">if</span> <span class="n">has_arg</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">call</span><span class="p">,</span> <span class="s1">&#39;mask&#39;</span><span class="p">):</span>
                    <span class="k">if</span> <span class="s1">&#39;mask&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                        <span class="c1"># If mask is explicitly passed to __call__,</span>
                        <span class="c1"># we should override the default mask.</span>
                        <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;mask&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">previous_mask</span>
            <span class="c1"># Handle automatic shape inference (only useful for Theano).</span>
            <span class="n">input_shape</span> <span class="o">=</span> <span class="n">_collect_input_shape</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

            <span class="c1"># Actually call the layer, collecting output(s), mask(s), and shape(s).</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="n">output_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_mask</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">previous_mask</span><span class="p">)</span>

            <span class="c1"># If the layer returns tensors from its inputs, unmodified,</span>
            <span class="c1"># we copy them to avoid loss of tensor metadata.</span>
            <span class="n">output_ls</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
            <span class="n">inputs_ls</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">output_ls_copy</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">output_ls</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">inputs_ls</span><span class="p">:</span>
                    <span class="n">x</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">output_ls_copy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_ls_copy</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">output_ls_copy</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">output_ls_copy</span>

            <span class="c1"># Infering the output shape is only relevant for Theano.</span>
            <span class="k">if</span> <span class="nb">all</span><span class="p">([</span><span class="n">s</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)]):</span>
                <span class="n">output_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_output_shape</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">input_shape</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="n">output_shape</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">input_shape</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">output_shape</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_mask</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">))</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_ls</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># Augment the mask to match the length of the output.</span>
                <span class="n">output_mask</span> <span class="o">=</span> <span class="p">[</span><span class="n">output_mask</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_ls</span><span class="p">)</span>

            <span class="c1"># Add an inbound node to the layer, so that it keeps track</span>
            <span class="c1"># of the call and of all new variables created during the call.</span>
            <span class="c1"># This also updates the layer history of the output tensor(s).</span>
            <span class="c1"># If the input tensor(s) had not previous Keras history,</span>
            <span class="c1"># this does nothing.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_add_inbound_node</span><span class="p">(</span><span class="n">input_tensors</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">output_tensors</span><span class="o">=</span><span class="n">output</span><span class="p">,</span>
                                   <span class="n">input_masks</span><span class="o">=</span><span class="n">previous_mask</span><span class="p">,</span> <span class="n">output_masks</span><span class="o">=</span><span class="n">output_mask</span><span class="p">,</span>
                                   <span class="n">input_shapes</span><span class="o">=</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">output_shapes</span><span class="o">=</span><span class="n">output_shape</span><span class="p">,</span>
                                   <span class="n">arguments</span><span class="o">=</span><span class="n">user_kwargs</span><span class="p">)</span>

            <span class="c1"># Apply activity regularizer if any:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;activity_regularizer&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">activity_regularizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">regularization_losses</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">activity_regularizer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">output</span><span class="p">)]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="n">regularization_losses</span><span class="p">,</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">inputs</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">output</span>

    <span class="k">def</span> <span class="nf">_add_inbound_node</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_tensors</span><span class="p">,</span> <span class="n">output_tensors</span><span class="p">,</span>
                          <span class="n">input_masks</span><span class="p">,</span> <span class="n">output_masks</span><span class="p">,</span>
                          <span class="n">input_shapes</span><span class="p">,</span> <span class="n">output_shapes</span><span class="p">,</span> <span class="n">arguments</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Internal method to create an inbound node for the layer.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            input_tensors: list of input tensors.</span>
<span class="sd">            output_tensors: list of output tensors.</span>
<span class="sd">            input_masks: list of input masks (a mask can be a tensor, or None).</span>
<span class="sd">            output_masks: list of output masks (a mask can be a tensor, or None).</span>
<span class="sd">            input_shapes: list of input shape tuples.</span>
<span class="sd">            output_shapes: list of output shape tuples.</span>
<span class="sd">            arguments: dictionary of keyword arguments that were passed to the</span>
<span class="sd">                `call` method of the layer at the call that created the node.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">input_tensors</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">input_tensors</span><span class="p">)</span>
        <span class="n">output_tensors</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">output_tensors</span><span class="p">)</span>
        <span class="n">input_masks</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">input_masks</span><span class="p">)</span>
        <span class="n">output_masks</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">output_masks</span><span class="p">)</span>
        <span class="n">input_shapes</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">input_shapes</span><span class="p">)</span>
        <span class="n">output_shapes</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">output_shapes</span><span class="p">)</span>

        <span class="c1"># Collect input tensor(s) coordinates.</span>
        <span class="n">inbound_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">node_indices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">tensor_indices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">input_tensors</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;_keras_history&#39;</span><span class="p">):</span>
                <span class="n">inbound_layer</span><span class="p">,</span> <span class="n">node_index</span><span class="p">,</span> <span class="n">tensor_index</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">_keras_history</span>
                <span class="n">inbound_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inbound_layer</span><span class="p">)</span>
                <span class="n">node_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span>
                <span class="n">tensor_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tensor_index</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">inbound_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
                <span class="n">node_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
                <span class="n">tensor_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>

        <span class="c1"># Create node, add it to inbound nodes.</span>
        <span class="n">Node</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">inbound_layers</span><span class="o">=</span><span class="n">inbound_layers</span><span class="p">,</span>
            <span class="n">node_indices</span><span class="o">=</span><span class="n">node_indices</span><span class="p">,</span>
            <span class="n">tensor_indices</span><span class="o">=</span><span class="n">tensor_indices</span><span class="p">,</span>
            <span class="n">input_tensors</span><span class="o">=</span><span class="n">input_tensors</span><span class="p">,</span>
            <span class="n">output_tensors</span><span class="o">=</span><span class="n">output_tensors</span><span class="p">,</span>
            <span class="n">input_masks</span><span class="o">=</span><span class="n">input_masks</span><span class="p">,</span>
            <span class="n">output_masks</span><span class="o">=</span><span class="n">output_masks</span><span class="p">,</span>
            <span class="n">input_shapes</span><span class="o">=</span><span class="n">input_shapes</span><span class="p">,</span>
            <span class="n">output_shapes</span><span class="o">=</span><span class="n">output_shapes</span><span class="p">,</span>
            <span class="n">arguments</span><span class="o">=</span><span class="n">arguments</span>
        <span class="p">)</span>

        <span class="c1"># Update tensor history, _keras_shape and _uses_learning_phase.</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">output_tensors</span><span class="p">)):</span>
            <span class="n">output_tensors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">_keras_shape</span> <span class="o">=</span> <span class="n">output_shapes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">uses_lp</span> <span class="o">=</span> <span class="nb">any</span><span class="p">([</span><span class="nb">getattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;_uses_learning_phase&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">input_tensors</span><span class="p">])</span>
            <span class="n">uses_lp</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;uses_learning_phase&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span> <span class="ow">or</span> <span class="n">uses_lp</span>
            <span class="n">output_tensors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">_uses_learning_phase</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">output_tensors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="s1">&#39;_uses_learning_phase&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span> <span class="ow">or</span> <span class="n">uses_lp</span>
            <span class="n">output_tensors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">_keras_history</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                                <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
                                                <span class="n">i</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes the output shape of the layer.</span>

<span class="sd">        Assumes that the layer will be built</span>
<span class="sd">        to match that input shape provided.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            input_shape: Shape tuple (tuple of integers)</span>
<span class="sd">                or list of shape tuples (one per output tensor of the layer).</span>
<span class="sd">                Shape tuples can include None for free dimensions,</span>
<span class="sd">                instead of an integer.</span>

<span class="sd">        # Returns</span>
<span class="sd">            An input shape tuple.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;get_output_shape_for&#39;</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Class `</span><span class="si">{}</span><span class="s2">.</span><span class="si">{}</span><span class="s2">` defines `get_output_shape_for` but does not override `compute_output_shape`. &quot;</span> <span class="o">+</span> \
                  <span class="s2">&quot;If this is a Keras 1 layer, please implement `compute_output_shape` to support Keras 2.&quot;</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__module__</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">),</span> <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">input_shape</span>

    <span class="k">def</span> <span class="nf">compute_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes an output mask tensor.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            inputs: Tensor or list of tensors.</span>
<span class="sd">            mask: Tensor or list of tensors.</span>

<span class="sd">        # Returns</span>
<span class="sd">            None or a tensor (or list of tensors,</span>
<span class="sd">                one per output tensor of the layer).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">supports_masking</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">m</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">mask</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Layer &#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span>
                                        <span class="s1">&#39; does not support masking, &#39;</span>
                                        <span class="s1">&#39;but was passed an input_mask: &#39;</span> <span class="o">+</span>
                                        <span class="nb">str</span><span class="p">(</span><span class="n">mask</span><span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Layer &#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span>
                                    <span class="s1">&#39; does not support masking, &#39;</span>
                                    <span class="s1">&#39;but was passed an input_mask: &#39;</span> <span class="o">+</span>
                                    <span class="nb">str</span><span class="p">(</span><span class="n">mask</span><span class="p">))</span>
            <span class="c1"># masking not explicitly supported: return None as mask</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="c1"># if masking is explicitly supported, by default</span>
        <span class="c1"># carry over the input mask</span>
        <span class="k">return</span> <span class="n">mask</span>

    <span class="k">def</span> <span class="nf">build</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Creates the layer weights.</span>

<span class="sd">        Must be implemented on all layers that have weights.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            input_shape: Keras tensor (future input to layer)</span>
<span class="sd">                or list/tuple of Keras tensors to reference</span>
<span class="sd">                for weight shape computations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">built</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">_get_node_attribute_at_index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_index</span><span class="p">,</span> <span class="n">attr</span><span class="p">,</span> <span class="n">attr_name</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieves an attribute (e.g. input_tensors) from a node.</span>

<span class="sd">        This is used to implement the methods:</span>
<span class="sd">            - get_input_shape_at</span>
<span class="sd">            - get_output_shape_at</span>
<span class="sd">            - get_input_at</span>
<span class="sd">            etc...</span>

<span class="sd">        # Arguments</span>
<span class="sd">            node_index: Integer index of the node from which</span>
<span class="sd">                to retrieve the attribute.</span>
<span class="sd">            attr: Exact node attribute name.</span>
<span class="sd">            attr_name: Human-readable attribute name, for error messages.</span>

<span class="sd">        # Returns</span>
<span class="sd">            The layer&#39;s attribute `attr` at the node of index `node_index`.</span>

<span class="sd">        # Raises</span>
<span class="sd">            RuntimeError: If the layer has no inbound nodes.</span>
<span class="sd">            ValueError: If the index is does not match any node.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;The layer has never been called &#39;</span>
                               <span class="s1">&#39;and thus has no defined &#39;</span> <span class="o">+</span> <span class="n">attr_name</span> <span class="o">+</span> <span class="s1">&#39;.&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">node_index</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Asked to get &#39;</span> <span class="o">+</span> <span class="n">attr_name</span> <span class="o">+</span>
                             <span class="s1">&#39; at node &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span> <span class="o">+</span>
                             <span class="s1">&#39;, but the layer has only &#39;</span> <span class="o">+</span>
                             <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">))</span> <span class="o">+</span> <span class="s1">&#39; inbound nodes.&#39;</span><span class="p">)</span>
        <span class="n">values</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">[</span><span class="n">node_index</span><span class="p">],</span> <span class="n">attr</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">values</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">values</span>

    <span class="k">def</span> <span class="nf">get_input_shape_at</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieves the input shape(s) of a layer at a given node.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            node_index: Integer, index of the node</span>
<span class="sd">                from which to retrieve the attribute.</span>
<span class="sd">                E.g. `node_index=0` will correspond to the</span>
<span class="sd">                first time the layer was called.</span>

<span class="sd">        # Returns</span>
<span class="sd">            A shape tuple</span>
<span class="sd">            (or list of shape tuples if the layer has multiple inputs).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="n">node_index</span><span class="p">,</span>
                                                 <span class="s1">&#39;input_shapes&#39;</span><span class="p">,</span>
                                                 <span class="s1">&#39;input shape&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_output_shape_at</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieves the output shape(s) of a layer at a given node.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            node_index: Integer, index of the node</span>
<span class="sd">                from which to retrieve the attribute.</span>
<span class="sd">                E.g. `node_index=0` will correspond to the</span>
<span class="sd">                first time the layer was called.</span>

<span class="sd">        # Returns</span>
<span class="sd">            A shape tuple</span>
<span class="sd">            (or list of shape tuples if the layer has multiple outputs).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="n">node_index</span><span class="p">,</span>
                                                 <span class="s1">&#39;output_shapes&#39;</span><span class="p">,</span>
                                                 <span class="s1">&#39;output shape&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_input_at</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieves the input tensor(s) of a layer at a given node.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            node_index: Integer, index of the node</span>
<span class="sd">                from which to retrieve the attribute.</span>
<span class="sd">                E.g. `node_index=0` will correspond to the</span>
<span class="sd">                first time the layer was called.</span>

<span class="sd">        # Returns</span>
<span class="sd">            A tensor (or list of tensors if the layer has multiple inputs).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="n">node_index</span><span class="p">,</span>
                                                 <span class="s1">&#39;input_tensors&#39;</span><span class="p">,</span>
                                                 <span class="s1">&#39;input&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_output_at</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieves the output tensor(s) of a layer at a given node.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            node_index: Integer, index of the node</span>
<span class="sd">                from which to retrieve the attribute.</span>
<span class="sd">                E.g. `node_index=0` will correspond to the</span>
<span class="sd">                first time the layer was called.</span>

<span class="sd">        # Returns</span>
<span class="sd">            A tensor (or list of tensors if the layer has multiple outputs).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="n">node_index</span><span class="p">,</span>
                                                 <span class="s1">&#39;output_tensors&#39;</span><span class="p">,</span>
                                                 <span class="s1">&#39;output&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_input_mask_at</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieves the input mask tensor(s) of a layer at a given node.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            node_index: Integer, index of the node</span>
<span class="sd">                from which to retrieve the attribute.</span>
<span class="sd">                E.g. `node_index=0` will correspond to the</span>
<span class="sd">                first time the layer was called.</span>

<span class="sd">        # Returns</span>
<span class="sd">            A mask tensor</span>
<span class="sd">            (or list of tensors if the layer has multiple inputs).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="n">node_index</span><span class="p">,</span>
                                                 <span class="s1">&#39;input_masks&#39;</span><span class="p">,</span>
                                                 <span class="s1">&#39;input mask&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_output_mask_at</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">node_index</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieves the output mask tensor(s) of a layer at a given node.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            node_index: Integer, index of the node</span>
<span class="sd">                from which to retrieve the attribute.</span>
<span class="sd">                E.g. `node_index=0` will correspond to the</span>
<span class="sd">                first time the layer was called.</span>

<span class="sd">        # Returns</span>
<span class="sd">            A mask tensor</span>
<span class="sd">            (or list of tensors if the layer has multiple outputs).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="n">node_index</span><span class="p">,</span>
                                                 <span class="s1">&#39;output_masks&#39;</span><span class="p">,</span>
                                                 <span class="s1">&#39;output mask&#39;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">input</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieves the input tensor(s) of a layer.</span>

<span class="sd">        Only applicable if the layer has exactly one inbound node,</span>
<span class="sd">        i.e. if it is connected to one incoming layer.</span>

<span class="sd">        # Returns</span>
<span class="sd">            Input tensor or list of input tensors.</span>

<span class="sd">        # Raises</span>
<span class="sd">            AttributeError: if the layer is connected to</span>
<span class="sd">            more than one incoming layers.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s1">&#39;Layer &#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span>
                                 <span class="s1">&#39; has multiple inbound nodes, &#39;</span>
                                 <span class="s1">&#39;hence the notion of &quot;layer input&quot; &#39;</span>
                                 <span class="s1">&#39;is ill-defined. &#39;</span>
                                 <span class="s1">&#39;Use `get_input_at(node_index)` instead.&#39;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s1">&#39;Layer &#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span>
                                 <span class="s1">&#39; is not connected, no input to return.&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;input_tensors&#39;</span><span class="p">,</span>
                                                 <span class="s1">&#39;input&#39;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">output</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieves the output tensor(s) of a layer.</span>

<span class="sd">        Only applicable if the layer has exactly one inbound node,</span>
<span class="sd">        i.e. if it is connected to one incoming layer.</span>

<span class="sd">        # Returns</span>
<span class="sd">            Output tensor or list of output tensors.</span>

<span class="sd">        # Raises</span>
<span class="sd">            AttributeError: if the layer is connected to</span>
<span class="sd">            more than one incoming layers.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s1">&#39;Layer &#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span>
                                 <span class="s1">&#39; has no inbound nodes.&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s1">&#39;Layer &#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span>
                                 <span class="s1">&#39; has multiple inbound nodes, &#39;</span>
                                 <span class="s1">&#39;hence the notion of &quot;layer output&quot; &#39;</span>
                                 <span class="s1">&#39;is ill-defined. &#39;</span>
                                 <span class="s1">&#39;Use `get_output_at(node_index)` instead.&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;output_tensors&#39;</span><span class="p">,</span>
                                                 <span class="s1">&#39;output&#39;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">input_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieves the input mask tensor(s) of a layer.</span>

<span class="sd">        Only applicable if the layer has exactly one inbound node,</span>
<span class="sd">        i.e. if it is connected to one incoming layer.</span>

<span class="sd">        # Returns</span>
<span class="sd">            Input mask tensor (potentially None) or list of input</span>
<span class="sd">            mask tensors.</span>

<span class="sd">        # Raises</span>
<span class="sd">            AttributeError: if the layer is connected to</span>
<span class="sd">            more than one incoming layers.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s1">&#39;Layer &#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span>
                                 <span class="s1">&#39; has multiple inbound nodes, &#39;</span> <span class="o">+</span>
                                 <span class="s1">&#39;hence the notion of &quot;layer input mask&quot; &#39;</span>
                                 <span class="s1">&#39;is ill-defined. &#39;</span>
                                 <span class="s1">&#39;Use `get_input_mask_at(node_index)` &#39;</span>
                                 <span class="s1">&#39;instead.&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;input_masks&#39;</span><span class="p">,</span>
                                                 <span class="s1">&#39;input mask&#39;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">output_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieves the output mask tensor(s) of a layer.</span>

<span class="sd">        Only applicable if the layer has exactly one inbound node,</span>
<span class="sd">        i.e. if it is connected to one incoming layer.</span>

<span class="sd">        # Returns</span>
<span class="sd">            Output mask tensor (potentially None) or list of output</span>
<span class="sd">            mask tensors.</span>

<span class="sd">        # Raises</span>
<span class="sd">            AttributeError: if the layer is connected to</span>
<span class="sd">            more than one incoming layers.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s1">&#39;Layer &#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span>
                                 <span class="s1">&#39; has multiple inbound nodes, &#39;</span>
                                 <span class="s1">&#39;hence the notion of &quot;layer output mask&quot; &#39;</span>
                                 <span class="s1">&#39;is ill-defined. &#39;</span>
                                 <span class="s1">&#39;Use `get_output_mask_at(node_index)` &#39;</span>
                                 <span class="s1">&#39;instead.&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_node_attribute_at_index</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;output_masks&#39;</span><span class="p">,</span>
                                                 <span class="s1">&#39;output mask&#39;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">input_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieves the input shape tuple(s) of a layer.</span>

<span class="sd">        Only applicable if the layer has exactly one inbound node,</span>
<span class="sd">        i.e. if it is connected to one incoming layer.</span>

<span class="sd">        # Returns</span>
<span class="sd">            Input shape tuple</span>
<span class="sd">            (or list of input shape tuples, one tuple per input tensor).</span>

<span class="sd">        # Raises</span>
<span class="sd">            AttributeError: if the layer is connected to</span>
<span class="sd">            more than one incoming layers.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s1">&#39;The layer has never been called &#39;</span>
                                 <span class="s1">&#39;and thus has no defined input shape.&#39;</span><span class="p">)</span>
        <span class="n">all_input_shapes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">input_shapes</span><span class="p">)</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">])</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_input_shapes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">input_shapes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">input_shapes</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shapes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">input_shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">input_shapes</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s1">&#39;The layer &quot;&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span> <span class="o">+</span>
                                 <span class="s1">&#39; has multiple inbound nodes, &#39;</span>
                                 <span class="s1">&#39;with different input shapes. Hence &#39;</span>
                                 <span class="s1">&#39;the notion of &quot;input shape&quot; is &#39;</span>
                                 <span class="s1">&#39;ill-defined for the layer. &#39;</span>
                                 <span class="s1">&#39;Use `get_input_shape_at(node_index)` &#39;</span>
                                 <span class="s1">&#39;instead.&#39;</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieves the output shape tuple(s) of a layer.</span>

<span class="sd">        Only applicable if the layer has one inbound node,</span>
<span class="sd">        or if all inbound nodes have the same output shape.</span>

<span class="sd">        # Returns</span>
<span class="sd">            Output shape tuple</span>
<span class="sd">            (or list of input shape tuples, one tuple per output tensor).</span>

<span class="sd">        # Raises</span>
<span class="sd">            AttributeError: if the layer is connected to</span>
<span class="sd">            more than one incoming layers.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s1">&#39;The layer has never been called &#39;</span>
                                 <span class="s1">&#39;and thus has no defined output shape.&#39;</span><span class="p">)</span>
        <span class="n">all_output_shapes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">output_shapes</span><span class="p">)</span> <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">])</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_output_shapes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">output_shapes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">output_shapes</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_shapes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">output_shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">output_shapes</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">AttributeError</span><span class="p">(</span><span class="s1">&#39;The layer &quot;&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span> <span class="o">+</span>
                                 <span class="s1">&#39; has multiple inbound nodes, &#39;</span>
                                 <span class="s1">&#39;with different output shapes. Hence &#39;</span>
                                 <span class="s1">&#39;the notion of &quot;output shape&quot; is &#39;</span>
                                 <span class="s1">&#39;ill-defined for the layer. &#39;</span>
                                 <span class="s1">&#39;Use `get_output_shape_at(node_index)` &#39;</span>
                                 <span class="s1">&#39;instead.&#39;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">add_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">losses</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Add losses to the layer.</span>

<span class="sd">        The loss may potentially be conditional on some inputs tensors,</span>
<span class="sd">        for instance activity losses are conditional on the layer&#39;s inputs.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            losses: loss tensor or list of loss tensors</span>
<span class="sd">                to add to the layer.</span>
<span class="sd">            inputs: input tensor or list of inputs tensors to mark</span>
<span class="sd">                the losses as conditional on these inputs.</span>
<span class="sd">                If None is passed, the loss is assumed unconditional</span>
<span class="sd">                (e.g. L2 weight regularization, which only depends</span>
<span class="sd">                on the layer&#39;s weights variables, not on any inputs tensors).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">losses</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">losses</span> <span class="o">==</span> <span class="p">[]:</span>
            <span class="k">return</span>
        <span class="c1"># Update self.losses</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_losses&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_losses</span> <span class="o">+=</span> <span class="n">losses</span>
        <span class="c1"># Update self._per_input_updates</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="n">inputs</span> <span class="o">==</span> <span class="p">[]:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">inputs_hash</span> <span class="o">=</span> <span class="n">_object_list_uid</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Updates indexed by None are unconditional</span>
            <span class="c1"># rather than input-dependent</span>
            <span class="n">inputs_hash</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">inputs_hash</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_per_input_losses</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_per_input_losses</span><span class="p">[</span><span class="n">inputs_hash</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_per_input_losses</span><span class="p">[</span><span class="n">inputs_hash</span><span class="p">]</span> <span class="o">+=</span> <span class="n">losses</span>

    <span class="k">def</span> <span class="nf">add_update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">updates</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Add updates to the layer.</span>

<span class="sd">        The updates may potentially be conditional on some inputs tensors,</span>
<span class="sd">        for instance batch norm updates are conditional on the layer&#39;s inputs.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            updates: update op or list of update ops</span>
<span class="sd">                to add to the layer.</span>
<span class="sd">            inputs: input tensor or list of inputs tensors to mark</span>
<span class="sd">                the updates as conditional on these inputs.</span>
<span class="sd">                If None is passed, the updates are assumed unconditional.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">updates</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">updates</span> <span class="o">==</span> <span class="p">[]:</span>
            <span class="k">return</span>
        <span class="c1"># Update self.updates</span>
        <span class="n">updates</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">updates</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;_updates&#39;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_updates</span> <span class="o">+=</span> <span class="n">updates</span>
        <span class="c1"># Update self._per_input_updates</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="n">inputs</span> <span class="o">==</span> <span class="p">[]:</span>
            <span class="n">inputs</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">inputs_hash</span> <span class="o">=</span> <span class="n">_object_list_uid</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Updates indexed by None are unconditional</span>
            <span class="c1"># rather than input-dependent</span>
            <span class="n">inputs_hash</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">inputs_hash</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_per_input_updates</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_per_input_updates</span><span class="p">[</span><span class="n">inputs_hash</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_per_input_updates</span><span class="p">[</span><span class="n">inputs_hash</span><span class="p">]</span> <span class="o">+=</span> <span class="n">updates</span>

    <span class="k">def</span> <span class="nf">get_updates_for</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">inputs_hash</span> <span class="o">=</span> <span class="n">_object_list_uid</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">inputs_hash</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">inputs_hash</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_per_input_updates</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_per_input_updates</span><span class="p">[</span><span class="n">inputs_hash</span><span class="p">]</span>
        <span class="k">return</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">get_losses_for</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">inputs_hash</span> <span class="o">=</span> <span class="n">_object_list_uid</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">inputs_hash</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">inputs_hash</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_per_input_losses</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_per_input_losses</span><span class="p">[</span><span class="n">inputs_hash</span><span class="p">]</span>
        <span class="k">return</span> <span class="p">[]</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable_weights</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">non_trainable_weights</span>

    <span class="k">def</span> <span class="nf">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Sets the weights of the layer, from Numpy arrays.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            weights: a list of Numpy arrays. The number</span>
<span class="sd">                of arrays and their shape must match</span>
<span class="sd">                number of the dimensions of the weights</span>
<span class="sd">                of the layer (i.e. it should match the</span>
<span class="sd">                output of `get_weights`).</span>

<span class="sd">        # Raises</span>
<span class="sd">            ValueError: If the provided weights list does not match the</span>
<span class="sd">                layer&#39;s specifications.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;You called `set_weights(weights)` on layer &quot;&#39;</span> <span class="o">+</span>
                             <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span>
                             <span class="s1">&#39;&quot; with a  weight list of length &#39;</span> <span class="o">+</span>
                             <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">))</span> <span class="o">+</span>
                             <span class="s1">&#39;, but the layer was expecting &#39;</span> <span class="o">+</span>
                             <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">))</span> <span class="o">+</span>
                             <span class="s1">&#39; weights. Provided weights: &#39;</span> <span class="o">+</span>
                             <span class="nb">str</span><span class="p">(</span><span class="n">weights</span><span class="p">)[:</span><span class="mi">50</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;...&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">params</span><span class="p">:</span>
            <span class="k">return</span>
        <span class="n">weight_value_tuples</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">param_values</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">batch_get_value</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">pv</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">param_values</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">pv</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Layer weight shape &#39;</span> <span class="o">+</span>
                                 <span class="nb">str</span><span class="p">(</span><span class="n">pv</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">+</span>
                                 <span class="s1">&#39; not compatible with &#39;</span>
                                 <span class="s1">&#39;provided weight shape &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
            <span class="n">weight_value_tuples</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="n">w</span><span class="p">))</span>
        <span class="n">K</span><span class="o">.</span><span class="n">batch_set_value</span><span class="p">(</span><span class="n">weight_value_tuples</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the current weights of the layer.</span>

<span class="sd">        # Returns</span>
<span class="sd">            Weights values as a list of numpy arrays.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="k">return</span> <span class="n">K</span><span class="o">.</span><span class="n">batch_get_value</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the config of the layer.</span>

<span class="sd">        A layer config is a Python dictionary (serializable)</span>
<span class="sd">        containing the configuration of a layer.</span>
<span class="sd">        The same layer can be reinstantiated later</span>
<span class="sd">        (without its trained weights) from this configuration.</span>

<span class="sd">        The config of a layer does not include connectivity</span>
<span class="sd">        information, nor the layer class name. These are handled</span>
<span class="sd">        by `Container` (one layer of abstraction above).</span>

<span class="sd">        # Returns</span>
<span class="sd">            Python dictionary.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                  <span class="s1">&#39;trainable&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable</span><span class="p">}</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;batch_input_shape&#39;</span><span class="p">):</span>
            <span class="n">config</span><span class="p">[</span><span class="s1">&#39;batch_input_shape&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_input_shape</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;dtype&#39;</span><span class="p">):</span>
            <span class="n">config</span><span class="p">[</span><span class="s1">&#39;dtype&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span>
        <span class="k">return</span> <span class="n">config</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_config</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">config</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Creates a layer from its config.</span>

<span class="sd">        This method is the reverse of `get_config`,</span>
<span class="sd">        capable of instantiating the same layer from the config</span>
<span class="sd">        dictionary. It does not handle layer connectivity</span>
<span class="sd">        (handled by Container), nor weights (handled by `set_weights`).</span>

<span class="sd">        # Arguments</span>
<span class="sd">            config: A Python dictionary, typically the</span>
<span class="sd">                output of get_config.</span>

<span class="sd">        # Returns</span>
<span class="sd">            A layer instance.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="o">**</span><span class="n">config</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">count_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Count the total number of scalars composing the weights.</span>

<span class="sd">        # Returns</span>
<span class="sd">            An integer count.</span>

<span class="sd">        # Raises</span>
<span class="sd">            RuntimeError: if the layer isn&#39;t yet built</span>
<span class="sd">                (in which case its weights aren&#39;t yet defined).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">built</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;Sequential&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">build</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;You tried to call `count_params` on &#39;</span> <span class="o">+</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;, but the layer isn</span><span class="se">\&#39;</span><span class="s1">t built. &#39;</span>
                                   <span class="s1">&#39;You can build it manually via: `&#39;</span> <span class="o">+</span>
                                   <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;.build(batch_input_shape)`.&#39;</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">sum</span><span class="p">([</span><span class="n">K</span><span class="o">.</span><span class="n">count_params</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">])</span>


<span class="k">class</span> <span class="nc">InputLayer</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Layer to be used as an entry point into a graph.</span>

<span class="sd">    It can either wrap an existing tensor (pass an `input_tensor` argument)</span>
<span class="sd">    or create its a placeholder tensor (pass arguments `input_shape`</span>
<span class="sd">    or `batch_input_shape` as well as `dtype`).</span>

<span class="sd">    # Arguments</span>
<span class="sd">        input_shape: Shape tuple, not including the batch axis.</span>
<span class="sd">        batch_size: Optional input batch size (integer or None).</span>
<span class="sd">        batch_input_shape: Shape tuple, including the batch axis.</span>
<span class="sd">        dtype: Datatype of the input.</span>
<span class="sd">        input_tensor: Optional tensor to use as layer input</span>
<span class="sd">            instead of creating a placeholder.</span>
<span class="sd">        sparse: Boolean, whether the placeholder created</span>
<span class="sd">            is meant to be sparse.</span>
<span class="sd">        name: Name of the layer (string).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@interfaces</span><span class="o">.</span><span class="n">legacy_input_support</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">batch_input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_tensor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">name</span><span class="p">:</span>
            <span class="n">prefix</span> <span class="o">=</span> <span class="s1">&#39;input&#39;</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">prefix</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">get_uid</span><span class="p">(</span><span class="n">prefix</span><span class="p">))</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">InputLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">built</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span> <span class="o">=</span> <span class="n">sparse</span>

        <span class="k">if</span> <span class="n">input_shape</span> <span class="ow">and</span> <span class="n">batch_input_shape</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Only provide the input_shape OR &#39;</span>
                             <span class="s1">&#39;batch_input_shape argument to &#39;</span>
                             <span class="s1">&#39;InputLayer, not both at the same time.&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">input_tensor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">batch_input_shape</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># If input_tensor is set, and batch_input_shape is not set:</span>
            <span class="c1"># Attempt automatic input shape inference.</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">batch_input_shape</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">input_shape</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">batch_input_shape</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;InputLayer was provided &#39;</span>
                                     <span class="s1">&#39;an input_tensor argument, &#39;</span>
                                     <span class="s1">&#39;but its input shape cannot be &#39;</span>
                                     <span class="s1">&#39;automatically inferred. &#39;</span>
                                     <span class="s1">&#39;You should pass an input_shape or &#39;</span>
                                     <span class="s1">&#39;batch_input_shape argument.&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">batch_input_shape</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">input_shape</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;An Input layer should be passed either &#39;</span>
                                 <span class="s1">&#39;a `batch_input_shape` or an `input_shape`.&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">batch_input_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">batch_input_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">batch_input_shape</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">dtype</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">input_tensor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">floatx</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">dtype</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">batch_input_shape</span> <span class="o">=</span> <span class="n">batch_input_shape</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">dtype</span>

        <span class="k">if</span> <span class="n">input_tensor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">is_placeholder</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">input_tensor</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">batch_input_shape</span><span class="p">,</span>
                                         <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
                                         <span class="n">sparse</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sparse</span><span class="p">,</span>
                                         <span class="n">name</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">is_placeholder</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="n">input_tensor</span><span class="o">.</span><span class="n">_keras_shape</span> <span class="o">=</span> <span class="n">batch_input_shape</span>
        <span class="c1"># Create an input node to add to self.outbound_node</span>
        <span class="c1"># and set output_tensors&#39; _keras_history.</span>
        <span class="n">input_tensor</span><span class="o">.</span><span class="n">_uses_learning_phase</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">input_tensor</span><span class="o">.</span><span class="n">_keras_history</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">Node</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
             <span class="n">inbound_layers</span><span class="o">=</span><span class="p">[],</span>
             <span class="n">node_indices</span><span class="o">=</span><span class="p">[],</span>
             <span class="n">tensor_indices</span><span class="o">=</span><span class="p">[],</span>
             <span class="n">input_tensors</span><span class="o">=</span><span class="p">[</span><span class="n">input_tensor</span><span class="p">],</span>
             <span class="n">output_tensors</span><span class="o">=</span><span class="p">[</span><span class="n">input_tensor</span><span class="p">],</span>
             <span class="n">input_masks</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span>
             <span class="n">output_masks</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span>
             <span class="n">input_shapes</span><span class="o">=</span><span class="p">[</span><span class="n">batch_input_shape</span><span class="p">],</span>
             <span class="n">output_shapes</span><span class="o">=</span><span class="p">[</span><span class="n">batch_input_shape</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;batch_input_shape&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_input_shape</span><span class="p">,</span>
                  <span class="s1">&#39;dtype&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
                  <span class="s1">&#39;sparse&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">sparse</span><span class="p">,</span>
                  <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">}</span>
        <span class="k">return</span> <span class="n">config</span>


<span class="k">def</span> <span class="nf">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
          <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">K</span><span class="o">.</span><span class="n">floatx</span><span class="p">(),</span> <span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
          <span class="n">tensor</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;`Input()` is used to instantiate a Keras tensor.</span>

<span class="sd">    A Keras tensor is a tensor object from the underlying backend</span>
<span class="sd">    (Theano or TensorFlow), which we augment with certain</span>
<span class="sd">    attributes that allow us to build a Keras model</span>
<span class="sd">    just by knowing the inputs and outputs of the model.</span>

<span class="sd">    For instance, if a, b and c are Keras tensors,</span>
<span class="sd">    it becomes possible to do:</span>
<span class="sd">    `model = Model(input=[a, b], output=c)`</span>

<span class="sd">    The added Keras attributes are:</span>
<span class="sd">        ._keras_shape: Integer shape tuple propagated</span>
<span class="sd">            via Keras-side shape inference.</span>
<span class="sd">        ._keras_history: Last layer applied to the tensor.</span>
<span class="sd">            the entire layer graph is retrievable from that layer,</span>
<span class="sd">            recursively.</span>

<span class="sd">    # Arguments</span>
<span class="sd">        shape: A shape tuple (integer), not including the batch size.</span>
<span class="sd">            For instance, `shape=(32,)` indicates that the expected input</span>
<span class="sd">            will be batches of 32-dimensional vectors.</span>
<span class="sd">        batch_shape: A shape tuple (integer), including the batch size.</span>
<span class="sd">            For instance, `batch_shape=(10, 32)` indicates that</span>
<span class="sd">            the expected input will be batches of 10 32-dimensional vectors.</span>
<span class="sd">            `batch_shape=(None, 32)` indicates batches of an arbitrary number</span>
<span class="sd">            of 32-dimensional vectors.</span>
<span class="sd">        name: An optional name string for the layer.</span>
<span class="sd">            Should be unique in a model (do not reuse the same name twice).</span>
<span class="sd">            It will be autogenerated if it isn&#39;t provided.</span>
<span class="sd">        dtype: The data type expected by the input, as a string</span>
<span class="sd">            (`float32`, `float64`, `int32`...)</span>
<span class="sd">        sparse: A boolean specifying whether the placeholder</span>
<span class="sd">            to be created is sparse.</span>
<span class="sd">        tensor: Optional existing tensor to wrap into the `Input` layer.</span>
<span class="sd">            If set, the layer will not create a placeholder tensor.</span>

<span class="sd">    # Returns</span>
<span class="sd">        A tensor.</span>

<span class="sd">    # Example</span>

<span class="sd">        ```python</span>
<span class="sd">        # this is a logistic regression in Keras</span>
<span class="sd">        x = Input(shape=(32,))</span>
<span class="sd">        y = Dense(16, activation=&#39;softmax&#39;)(x)</span>
<span class="sd">        model = Model(x, y)</span>
<span class="sd">        ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">batch_shape</span> <span class="ow">and</span> <span class="n">tensor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">shape</span><span class="p">,</span> <span class="p">(</span><span class="s1">&#39;Please provide to Input either a `shape`&#39;</span>
                       <span class="s1">&#39; or a `batch_shape` argument. Note that &#39;</span>
                       <span class="s1">&#39;`shape` does not include the batch &#39;</span>
                       <span class="s1">&#39;dimension.&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">shape</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">batch_shape</span><span class="p">:</span>
        <span class="n">batch_shape</span> <span class="o">=</span> <span class="p">(</span><span class="kc">None</span><span class="p">,)</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">input_layer</span> <span class="o">=</span> <span class="n">InputLayer</span><span class="p">(</span><span class="n">batch_input_shape</span><span class="o">=</span><span class="n">batch_shape</span><span class="p">,</span>
                             <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
                             <span class="n">sparse</span><span class="o">=</span><span class="n">sparse</span><span class="p">,</span>
                             <span class="n">input_tensor</span><span class="o">=</span><span class="n">tensor</span><span class="p">)</span>
    <span class="c1"># Return tensor including _keras_shape and _keras_history.</span>
    <span class="c1"># Note that in this case train_output and test_output are the same pointer.</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="n">input_layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">output_tensors</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">outputs</span>


<span class="k">class</span> <span class="nc">Container</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;A Container is a directed acyclic graph of layers.</span>

<span class="sd">    It is the topological form of a &quot;model&quot;. A Model</span>
<span class="sd">    is simply a Container with added training routines.</span>

<span class="sd">    # Properties</span>
<span class="sd">        name</span>
<span class="sd">        inputs</span>
<span class="sd">        outputs</span>
<span class="sd">        input_layers</span>
<span class="sd">        output_layers</span>
<span class="sd">        input_spec (list of class instances)</span>
<span class="sd">            each entry describes one required input:</span>
<span class="sd">                - ndim</span>
<span class="sd">                - dtype</span>
<span class="sd">        trainable (boolean)</span>
<span class="sd">        input_shape</span>
<span class="sd">        output_shape</span>
<span class="sd">        inbound_nodes: list of nodes</span>
<span class="sd">        outbound_nodes: list of nodes</span>
<span class="sd">        trainable_weights (list of variables)</span>
<span class="sd">        non_trainable_weights (list of variables)</span>

<span class="sd">    # Methods</span>
<span class="sd">        summary</span>
<span class="sd">        get_layer</span>
<span class="sd">        get_weights</span>
<span class="sd">        set_weights</span>
<span class="sd">        get_config</span>
<span class="sd">        compute_output_shape</span>

<span class="sd">    # Class Methods</span>
<span class="sd">        from_config</span>

<span class="sd">    # Raises</span>
<span class="sd">        TypeError: if input tensors are not Keras tensors from InputLayer objects</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@interfaces</span><span class="o">.</span><span class="n">legacy_model_constructor_support</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Handle `name` argument.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">name</span><span class="p">:</span>
            <span class="n">prefix</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">prefix</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">get_uid</span><span class="p">(</span><span class="n">prefix</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">supports_masking</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainable</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_per_input_losses</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_per_input_updates</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Container-specific properties.</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>  <span class="c1"># Tensor or list of tensors.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">inputs</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">outputs</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">outputs</span><span class="p">]</span>

        <span class="c1"># Check for redundancy in inputs.</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">))</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;The list of inputs passed to the model &#39;</span>
                             <span class="s1">&#39;is redundant. &#39;</span>
                             <span class="s1">&#39;All inputs should only appear once.&#39;</span>
                             <span class="s1">&#39; Found: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">))</span>

        <span class="c1"># Check for redundancy in outputs.</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">))</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;The list of outputs passed to the model &#39;</span>
                          <span class="s1">&#39;is redundant. &#39;</span>
                          <span class="s1">&#39;All outputs should only appear once.&#39;</span>
                          <span class="s1">&#39; Found: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">))</span>

        <span class="c1"># List of initial layers (1 to 1 mapping with self.inputs,</span>
        <span class="c1"># hence the same layer might appear twice)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_layers_node_indices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_layers_tensor_indices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># list of layers (1 to 1 mapping with self.inputs,</span>
        <span class="c1"># hence the same layer might appear twice)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_layers_node_indices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_layers_tensor_indices</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># all layers in order of horizontal graph traversal.</span>
        <span class="c1"># Entries are unique. Includes input and output layers.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># This is for performance optimization</span>
        <span class="c1"># when calling the Container on new inputs.</span>
        <span class="c1"># every time the Container is called on a set on input tensors,</span>
        <span class="c1"># we compute the output tensors,</span>
        <span class="c1"># output masks and output shapes in one pass,</span>
        <span class="c1"># then cache them here. When one of these output is queried later,</span>
        <span class="c1"># we retrieve it from there instead of recomputing it.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_output_mask_cache</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_output_tensor_cache</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape_cache</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># User-provided arguments validation.</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">:</span>
            <span class="c1"># Check that x is a Keras tensor.</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;_keras_history&#39;</span><span class="p">):</span>
                <span class="n">cls_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Input tensors to a &#39;</span> <span class="o">+</span> <span class="n">cls_name</span> <span class="o">+</span> <span class="s1">&#39; &#39;</span> <span class="o">+</span>
                                <span class="s1">&#39;must be Keras tensors. Found: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span>
                                <span class="s1">&#39; (missing Keras metadata).&#39;</span><span class="p">)</span>
            <span class="c1"># Check that x is an input tensor.</span>
            <span class="n">layer</span><span class="p">,</span> <span class="n">node_index</span><span class="p">,</span> <span class="n">tensor_index</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">_keras_history</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">or</span> <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">inbound_nodes</span> <span class="ow">and</span> <span class="n">layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">inbound_layers</span><span class="p">):</span>
                <span class="n">cls_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">cls_name</span> <span class="o">+</span> <span class="s1">&#39; inputs must come from &#39;</span>
                              <span class="s1">&#39;a Keras Input layer, &#39;</span>
                              <span class="s1">&#39;they cannot be the output of &#39;</span>
                              <span class="s1">&#39;a previous non-Input layer. &#39;</span>
                              <span class="s1">&#39;Here, a tensor specified as &#39;</span>
                              <span class="s1">&#39;input to &quot;&#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span>
                              <span class="s1">&#39;&quot; was not an Input tensor, &#39;</span>
                              <span class="s1">&#39;it was generated by layer &#39;</span> <span class="o">+</span>
                              <span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;.</span><span class="se">\n</span><span class="s1">&#39;</span>
                              <span class="s1">&#39;Note that input tensors are &#39;</span>
                              <span class="s1">&#39;instantiated via `tensor = Input(shape)`.</span><span class="se">\n</span><span class="s1">&#39;</span>
                              <span class="s1">&#39;The tensor that caused the issue was: &#39;</span> <span class="o">+</span>
                              <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">name</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;_keras_history&#39;</span><span class="p">):</span>
                <span class="n">cls_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Output tensors to a &#39;</span> <span class="o">+</span> <span class="n">cls_name</span> <span class="o">+</span> <span class="s1">&#39; must be &#39;</span>
                                <span class="s1">&#39;Keras tensors. Found: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="c1"># Build self.output_layers:</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
            <span class="n">layer</span><span class="p">,</span> <span class="n">node_index</span><span class="p">,</span> <span class="n">tensor_index</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">_keras_history</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_layers_node_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_layers_tensor_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tensor_index</span><span class="p">)</span>

        <span class="c1"># Fill in the output mask cache.</span>
        <span class="n">masks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">:</span>
            <span class="n">layer</span><span class="p">,</span> <span class="n">node_index</span><span class="p">,</span> <span class="n">tensor_index</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">_keras_history</span>
            <span class="n">node</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">[</span><span class="n">node_index</span><span class="p">]</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">output_masks</span><span class="p">[</span><span class="n">tensor_index</span><span class="p">]</span>
            <span class="n">masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
        <span class="n">mask_cache_key</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">])</span>
        <span class="n">mask_cache_key</span> <span class="o">+=</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">masks</span><span class="p">])</span>
        <span class="n">masks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
            <span class="n">layer</span><span class="p">,</span> <span class="n">node_index</span><span class="p">,</span> <span class="n">tensor_index</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">_keras_history</span>
            <span class="n">node</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">[</span><span class="n">node_index</span><span class="p">]</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">output_masks</span><span class="p">[</span><span class="n">tensor_index</span><span class="p">]</span>
            <span class="n">masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">masks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">masks</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_output_mask_cache</span><span class="p">[</span><span class="n">mask_cache_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">mask</span>

        <span class="c1"># Build self.input_layers:</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">:</span>
            <span class="n">layer</span><span class="p">,</span> <span class="n">node_index</span><span class="p">,</span> <span class="n">tensor_index</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">_keras_history</span>
            <span class="c1"># It&#39;s supposed to be an input layer, so only one node</span>
            <span class="c1"># and one tensor output.</span>
            <span class="k">assert</span> <span class="n">node_index</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="k">assert</span> <span class="n">tensor_index</span> <span class="o">==</span> <span class="mi">0</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_layers_node_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_index</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_layers_tensor_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tensor_index</span><span class="p">)</span>

        <span class="c1"># Build self.input_names and self.output_names.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_names</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_names</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_feed_input_names</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_feed_inputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_feed_input_shapes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_layers</span><span class="p">):</span>
            <span class="c1"># Check that layer is an InputLayer.</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">InputLayer</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="s1">&#39;Input layers to a `Model` must be `InputLayer` objects. &#39;</span>
                    <span class="s1">&#39;Received inputs: </span><span class="si">{}</span><span class="s1">. &#39;</span>
                    <span class="s1">&#39;Input </span><span class="si">{}</span><span class="s1"> (0-based) originates &#39;</span>
                    <span class="s1">&#39;from layer type `</span><span class="si">{}</span><span class="s1">`.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span>
                                                   <span class="n">i</span><span class="p">,</span>
                                                   <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">is_placeholder</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_feed_input_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_feed_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">input</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_feed_input_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">_keras_shape</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layers</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">internal_input_shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">_keras_shape</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">internal_output_shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">_keras_shape</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">]</span>

        <span class="c1"># Container_nodes: set of nodes included in the graph</span>
        <span class="c1"># (not all nodes included in the layers</span>
        <span class="c1"># are relevant to the current graph).</span>
        <span class="n">container_nodes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>  <span class="c1"># ids of all nodes relevant to the Container</span>
        <span class="n">nodes_depths</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># dict {node: depth value}</span>
        <span class="n">layers_depths</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># dict {layer: depth value}</span>
        <span class="n">layer_indices</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># dict {layer: index in traversal}</span>
        <span class="n">nodes_in_decreasing_depth</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">def</span> <span class="nf">build_map_of_graph</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">finished_nodes</span><span class="p">,</span> <span class="n">nodes_in_progress</span><span class="p">,</span>
                               <span class="n">layer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">node_index</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tensor_index</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Builds a map of the graph of layers.</span>

<span class="sd">            This recursively updates the map `layer_indices`,</span>
<span class="sd">            the list `nodes_in_decreasing_depth` and the set `container_nodes`.</span>

<span class="sd">            # Arguments</span>
<span class="sd">                tensor: Some tensor in a graph.</span>
<span class="sd">                finished_nodes: Set of nodes whose subgraphs have been traversed</span>
<span class="sd">                    completely. Useful to prevent duplicated work.</span>
<span class="sd">                nodes_in_progress: Set of nodes that are currently active on the</span>
<span class="sd">                    recursion stack. Useful to detect cycles.</span>
<span class="sd">                layer: Layer from which `tensor` comes from. If not provided,</span>
<span class="sd">                    will be obtained from `tensor._keras_history`.</span>
<span class="sd">                node_index: Node index from which `tensor` comes from.</span>
<span class="sd">                tensor_index: Tensor_index from which `tensor` comes from.</span>

<span class="sd">            # Raises</span>
<span class="sd">                RuntimeError: if a cycle is detected.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">layer</span> <span class="ow">or</span> <span class="n">node_index</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">tensor_index</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">layer</span><span class="p">,</span> <span class="n">node_index</span><span class="p">,</span> <span class="n">tensor_index</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">_keras_history</span>
            <span class="n">node</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">[</span><span class="n">node_index</span><span class="p">]</span>

            <span class="c1"># Prevent cycles.</span>
            <span class="k">if</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes_in_progress</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s1">&#39;The tensor &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39; at layer &quot;&#39;</span> <span class="o">+</span>
                    <span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;&quot; is part of a cycle.&#39;</span><span class="p">)</span>

            <span class="c1"># Don&#39;t repeat work for shared subgraphs</span>
            <span class="k">if</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">finished_nodes</span><span class="p">:</span>
                <span class="k">return</span>

            <span class="c1"># Update container_nodes.</span>
            <span class="n">container_nodes</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_node_key</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">node_index</span><span class="p">))</span>

            <span class="c1"># Store the traversal order for layer sorting.</span>
            <span class="k">if</span> <span class="n">layer</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">layer_indices</span><span class="p">:</span>
                <span class="n">layer_indices</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_indices</span><span class="p">)</span>

            <span class="n">nodes_in_progress</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

            <span class="c1"># Propagate to all previous tensors connected to this node.</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">inbound_layers</span><span class="p">)):</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">input_tensors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">layer</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">inbound_layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">node_index</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">node_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">tensor_index</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">tensor_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">build_map_of_graph</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">finished_nodes</span><span class="p">,</span> <span class="n">nodes_in_progress</span><span class="p">,</span>
                                   <span class="n">layer</span><span class="p">,</span> <span class="n">node_index</span><span class="p">,</span> <span class="n">tensor_index</span><span class="p">)</span>

            <span class="n">finished_nodes</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
            <span class="n">nodes_in_progress</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

            <span class="n">nodes_in_decreasing_depth</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

        <span class="n">finished_nodes</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">nodes_in_progress</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
            <span class="n">build_map_of_graph</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">finished_nodes</span><span class="p">,</span> <span class="n">nodes_in_progress</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">nodes_in_decreasing_depth</span><span class="p">):</span>
            <span class="c1"># If the depth is not set, the node has no outbound nodes (depth 0).</span>
            <span class="n">depth</span> <span class="o">=</span> <span class="n">nodes_depths</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

            <span class="c1"># Update the depth of the corresponding layer</span>
            <span class="n">previous_depth</span> <span class="o">=</span> <span class="n">layers_depths</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">outbound_layer</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="c1"># If we&#39;ve seen this layer before at a higher depth, we should use that depth instead</span>
            <span class="c1"># of the node depth.  This is necessary for shared layers that have inputs at different</span>
            <span class="c1"># depth levels in the graph.</span>
            <span class="n">depth</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">depth</span><span class="p">,</span> <span class="n">previous_depth</span><span class="p">)</span>
            <span class="n">layers_depths</span><span class="p">[</span><span class="n">node</span><span class="o">.</span><span class="n">outbound_layer</span><span class="p">]</span> <span class="o">=</span> <span class="n">depth</span>
            <span class="n">nodes_depths</span><span class="p">[</span><span class="n">node</span><span class="p">]</span> <span class="o">=</span> <span class="n">depth</span>

            <span class="c1"># Update the depth of inbound nodes.</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">inbound_layers</span><span class="p">)):</span>
                <span class="n">inbound_layer</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">inbound_layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">node_index</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">node_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">inbound_node</span> <span class="o">=</span> <span class="n">inbound_layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">[</span><span class="n">node_index</span><span class="p">]</span>
                <span class="n">previous_depth</span> <span class="o">=</span> <span class="n">nodes_depths</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">inbound_node</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
                <span class="n">nodes_depths</span><span class="p">[</span><span class="n">inbound_node</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">previous_depth</span><span class="p">)</span>

        <span class="c1"># Build a dict {depth: list of nodes with this depth}</span>
        <span class="n">nodes_by_depth</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">node</span><span class="p">,</span> <span class="n">depth</span> <span class="ow">in</span> <span class="n">nodes_depths</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">depth</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">nodes_by_depth</span><span class="p">:</span>
                <span class="n">nodes_by_depth</span><span class="p">[</span><span class="n">depth</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">nodes_by_depth</span><span class="p">[</span><span class="n">depth</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>

        <span class="c1"># Build a dict {depth: list of layers with this depth}</span>
        <span class="n">layers_by_depth</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">layer</span><span class="p">,</span> <span class="n">depth</span> <span class="ow">in</span> <span class="n">layers_depths</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">depth</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">layers_by_depth</span><span class="p">:</span>
                <span class="n">layers_by_depth</span><span class="p">[</span><span class="n">depth</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">layers_by_depth</span><span class="p">[</span><span class="n">depth</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>

        <span class="c1"># Get sorted list of layer depths.</span>
        <span class="n">depth_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">layers_by_depth</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">depth_keys</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Set self.layers and self.layers_by_depth.</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">depth</span> <span class="ow">in</span> <span class="n">depth_keys</span><span class="p">:</span>
            <span class="n">layers_for_depth</span> <span class="o">=</span> <span class="n">layers_by_depth</span><span class="p">[</span><span class="n">depth</span><span class="p">]</span>
            <span class="c1"># Container.layers needs to have a deterministic order:</span>
            <span class="c1"># here we order them by traversal order.</span>
            <span class="n">layers_for_depth</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">layer_indices</span><span class="p">[</span><span class="n">x</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">layers_for_depth</span><span class="p">:</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">layers</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers_by_depth</span> <span class="o">=</span> <span class="n">layers_by_depth</span>

        <span class="c1"># Get sorted list of node depths.</span>
        <span class="n">depth_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">nodes_by_depth</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">depth_keys</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># Check that all tensors required are computable.</span>
        <span class="c1"># computable_tensors: all tensors in the graph</span>
        <span class="c1"># that can be computed from the inputs provided.</span>
        <span class="n">computable_tensors</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">:</span>
            <span class="n">computable_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">layers_with_complete_input</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># To provide a better error msg.</span>
        <span class="k">for</span> <span class="n">depth</span> <span class="ow">in</span> <span class="n">depth_keys</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes_by_depth</span><span class="p">[</span><span class="n">depth</span><span class="p">]:</span>
                <span class="n">layer</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">outbound_layer</span>
                <span class="k">if</span> <span class="n">layer</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">input_tensors</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">computable_tensors</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                                <span class="s1">&#39;Graph disconnected: &#39;</span>
                                <span class="s1">&#39;cannot obtain value for tensor &#39;</span> <span class="o">+</span>
                                <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39; at layer &quot;&#39;</span> <span class="o">+</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;&quot;. &#39;</span>
                                <span class="s1">&#39;The following previous layers &#39;</span>
                                <span class="s1">&#39;were accessed without issue: &#39;</span> <span class="o">+</span>
                                <span class="nb">str</span><span class="p">(</span><span class="n">layers_with_complete_input</span><span class="p">))</span>
                    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">node</span><span class="o">.</span><span class="n">output_tensors</span><span class="p">:</span>
                        <span class="n">computable_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                    <span class="n">layers_with_complete_input</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>

        <span class="c1"># Set self.nodes and self.nodes_by_depth.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">container_nodes</span> <span class="o">=</span> <span class="n">container_nodes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nodes_by_depth</span> <span class="o">=</span> <span class="n">nodes_by_depth</span>

        <span class="c1"># Ensure name unicity, which will be crucial for serialization</span>
        <span class="c1"># (since serialized nodes refer to layers by their name).</span>
        <span class="n">all_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">all_names</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">all_names</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;The name &quot;&#39;</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;&quot; is used &#39;</span> <span class="o">+</span>
                                   <span class="nb">str</span><span class="p">(</span><span class="n">all_names</span><span class="o">.</span><span class="n">count</span><span class="p">(</span><span class="n">name</span><span class="p">))</span> <span class="o">+</span>
                                   <span class="s1">&#39; times in the model. &#39;</span>
                                   <span class="s1">&#39;All layer names should be unique. &#39;</span>
                                   <span class="s1">&#39;Layer names: &#39;</span><span class="p">,</span> <span class="n">all_names</span><span class="p">)</span>

        <span class="c1"># Layer parameters.</span>
        <span class="c1"># The new container starts with a single inbound node</span>
        <span class="c1"># for its inputs, and no outbound nodes.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outbound_nodes</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># Will be appended to by future calls to __call__</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">inbound_nodes</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># Will be appended to below, and by future calls to __call__</span>
        <span class="c1"># Create the node linking internal inputs to internal outputs.</span>
        <span class="n">Node</span><span class="p">(</span><span class="n">outbound_layer</span><span class="o">=</span><span class="bp">self</span><span class="p">,</span>
             <span class="n">inbound_layers</span><span class="o">=</span><span class="p">[],</span>
             <span class="n">node_indices</span><span class="o">=</span><span class="p">[],</span>
             <span class="n">tensor_indices</span><span class="o">=</span><span class="p">[],</span>
             <span class="n">input_tensors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span>
             <span class="n">output_tensors</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">,</span>
             <span class="c1"># No container-level masking for now.</span>
             <span class="n">input_masks</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">],</span>
             <span class="n">output_masks</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">],</span>
             <span class="n">input_shapes</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">_keras_shape</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">],</span>
             <span class="n">output_shapes</span><span class="o">=</span><span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">_keras_shape</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">built</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1"># The following are implemented as property functions:</span>
        <span class="c1"># self.trainable_weights</span>
        <span class="c1"># self.non_trainable_weights</span>
        <span class="c1"># self.input_spec</span>

    <span class="k">def</span> <span class="nf">get_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieves a layer based on either its name (unique) or index.</span>

<span class="sd">        Indices are based on order of horizontal graph traversal (bottom-up).</span>

<span class="sd">        # Arguments</span>
<span class="sd">            name: String, name of layer.</span>
<span class="sd">            index: Integer, index of layer.</span>

<span class="sd">        # Returns</span>
<span class="sd">            A layer instance.</span>

<span class="sd">        # Raises</span>
<span class="sd">            ValueError: In case of invalid layer name or index.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># It would be unreliable to build a dictionary</span>
        <span class="c1"># based on layer names, because names can potentially</span>
        <span class="c1"># be changed at any point by the user</span>
        <span class="c1"># without the container being notified of it.</span>
        <span class="k">if</span> <span class="n">index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">index</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Was asked to retrieve layer at index &#39;</span> <span class="o">+</span>
                                 <span class="nb">str</span><span class="p">(</span><span class="n">index</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39; but model only has &#39;</span> <span class="o">+</span>
                                 <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">))</span> <span class="o">+</span> <span class="s1">&#39; layers.&#39;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">name</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Provide either a layer name or layer index.&#39;</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">name</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">layer</span>

        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;No such layer: &#39;</span> <span class="o">+</span> <span class="n">name</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">updates</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieve the model&#39;s updates.</span>

<span class="sd">        Will only include updates that are either</span>
<span class="sd">        inconditional, or conditional on inputs to this model</span>
<span class="sd">        (e.g. will not include updates that depend on tensors</span>
<span class="sd">        that aren&#39;t inputs to this model).</span>

<span class="sd">        # Returns</span>
<span class="sd">            A list of update ops.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">updates</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;updates&#39;</span><span class="p">):</span>
                <span class="c1"># Collect updates that are dependent on inputs</span>
                <span class="c1"># that are part of the model.</span>
                <span class="k">for</span> <span class="n">node_index</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">):</span>
                    <span class="n">node_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node_key</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">node_index</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">node_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">container_nodes</span><span class="p">:</span>
                        <span class="c1"># The model owns this layer node.</span>
                        <span class="n">inputs</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">input_tensors</span>
                        <span class="n">updates</span> <span class="o">+=</span> <span class="n">layer</span><span class="o">.</span><span class="n">get_updates_for</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
                <span class="c1"># Collect unconditional updates.</span>
                <span class="n">updates</span> <span class="o">+=</span> <span class="n">layer</span><span class="o">.</span><span class="n">get_updates_for</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">updates</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">losses</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieve the model&#39;s losses.</span>

<span class="sd">        Will only include losses that are either</span>
<span class="sd">        inconditional, or conditional on inputs to this model</span>
<span class="sd">        (e.g. will not include losses that depend on tensors</span>
<span class="sd">        that aren&#39;t inputs to this model).</span>

<span class="sd">        # Returns</span>
<span class="sd">            A list of loss tensors.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Retrieve losses for all internal layers.</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;losses&#39;</span><span class="p">):</span>
                <span class="c1"># Collect losses that are dependent on inputs</span>
                <span class="c1"># that are part of the model.</span>
                <span class="k">for</span> <span class="n">node_index</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">):</span>
                    <span class="n">node_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node_key</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">node_index</span><span class="p">)</span>
                    <span class="k">if</span> <span class="n">node_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">container_nodes</span><span class="p">:</span>
                        <span class="c1"># The model owns this layer node.</span>
                        <span class="n">inputs</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">input_tensors</span>
                        <span class="n">losses</span> <span class="o">+=</span> <span class="n">layer</span><span class="o">.</span><span class="n">get_losses_for</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
                <span class="c1"># Collect unconditional losses.</span>
                <span class="n">losses</span> <span class="o">+=</span> <span class="n">layer</span><span class="o">.</span><span class="n">get_losses_for</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
        <span class="c1"># Add any potential unconditional model-level loss.</span>
        <span class="n">losses</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_losses_for</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">losses</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">uses_learning_phase</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">any</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">_uses_learning_phase</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">])</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">stateful</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">any</span><span class="p">([(</span><span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;stateful&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">layer</span><span class="o">.</span><span class="n">stateful</span><span class="p">)</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">reset_states</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;reset_states&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;stateful&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
                <span class="n">layer</span><span class="o">.</span><span class="n">reset_states</span><span class="p">()</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">state_updates</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns the `updates` from all layers that are stateful.</span>

<span class="sd">        This is useful for separating training updates and</span>
<span class="sd">        state updates, e.g. when we need to update a layer&#39;s internal state</span>
<span class="sd">        during prediction.</span>

<span class="sd">        # Returns</span>
<span class="sd">            A list of update ops.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">state_updates</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;stateful&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;updates&#39;</span><span class="p">):</span>
                    <span class="n">state_updates</span> <span class="o">+=</span> <span class="n">layer</span><span class="o">.</span><span class="n">updates</span>
        <span class="k">return</span> <span class="n">state_updates</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">trainable_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[]</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">+=</span> <span class="n">layer</span><span class="o">.</span><span class="n">trainable_weights</span>
        <span class="k">return</span> <span class="n">weights</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">non_trainable_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">+=</span> <span class="n">layer</span><span class="o">.</span><span class="n">non_trainable_weights</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainable</span><span class="p">:</span>
            <span class="n">trainable_weights</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
                <span class="n">trainable_weights</span> <span class="o">+=</span> <span class="n">layer</span><span class="o">.</span><span class="n">trainable_weights</span>
            <span class="k">return</span> <span class="n">trainable_weights</span> <span class="o">+</span> <span class="n">weights</span>
        <span class="k">return</span> <span class="n">weights</span>

    <span class="k">def</span> <span class="nf">get_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Retrieves the weights of the model.</span>

<span class="sd">        # Returns</span>
<span class="sd">            A flat list of Numpy arrays.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">+=</span> <span class="n">layer</span><span class="o">.</span><span class="n">weights</span>
        <span class="k">return</span> <span class="n">K</span><span class="o">.</span><span class="n">batch_get_value</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Sets the weights of the model.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            weights: A list of Numpy arrays with shapes and types matching</span>
<span class="sd">                the output of `model.get_weights()`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tuples</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">num_param</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span>
            <span class="n">layer_weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[:</span><span class="n">num_param</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">sw</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">layer_weights</span><span class="p">):</span>
                <span class="n">tuples</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">sw</span><span class="p">,</span> <span class="n">w</span><span class="p">))</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">num_param</span><span class="p">:]</span>
        <span class="n">K</span><span class="o">.</span><span class="n">batch_set_value</span><span class="p">(</span><span class="n">tuples</span><span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">input_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Gets the model&#39;s input specs.</span>

<span class="sd">        # Returns</span>
<span class="sd">            A list of `InputSpec` instances (one per input to the model)</span>
<span class="sd">                or a single instance if the model has only one input.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">specs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s1">&#39;input_layers&#39;</span><span class="p">,</span> <span class="p">[]):</span>
            <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">input_spec</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">specs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">input_spec</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Layer &#39;</span> <span class="o">+</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span>
                                    <span class="s1">&#39; has an input_spec attribute that &#39;</span>
                                    <span class="s1">&#39;is not a list. We expect a list. &#39;</span>
                                    <span class="s1">&#39;Found input_spec = &#39;</span> <span class="o">+</span>
                                    <span class="nb">str</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">input_spec</span><span class="p">))</span>
                <span class="n">specs</span> <span class="o">+=</span> <span class="n">layer</span><span class="o">.</span><span class="n">input_spec</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">specs</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">specs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">specs</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Call the model on new inputs.</span>

<span class="sd">        In this case `call` just reapplies</span>
<span class="sd">        all ops in the graph to the new inputs</span>
<span class="sd">        (e.g. build a new computational graph from the provided inputs).</span>

<span class="sd">        A model is callable on non-Keras tensors.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            inputs: A tensor or list of tensors.</span>
<span class="sd">            mask: A mask or list of masks. A mask can be</span>
<span class="sd">                either a tensor or None (no mask).</span>

<span class="sd">        # Returns</span>
<span class="sd">            A tensor if there is a single output, or</span>
<span class="sd">            a list of tensors if there are more than one outputs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">masks</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">))]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">masks</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
        <span class="n">cache_key</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">])</span>
        <span class="n">cache_key</span> <span class="o">+=</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">masks</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">cache_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_tensor_cache</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_tensor_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">output_tensors</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_internal_graph</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">masks</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">output_tensors</span>

    <span class="k">def</span> <span class="nf">compute_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">masks</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">))]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">masks</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
        <span class="n">cache_key</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">])</span>
        <span class="n">cache_key</span> <span class="o">+=</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">masks</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">cache_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_mask_cache</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_mask_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">output_masks</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_internal_graph</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">masks</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">output_masks</span>

    <span class="k">def</span> <span class="nf">compute_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="p">):</span>
        <span class="n">input_shapes</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shapes</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_layers</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Invalid input_shape argument &#39;</span> <span class="o">+</span>
                             <span class="nb">str</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;: model has &#39;</span> <span class="o">+</span>
                             <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_layers</span><span class="p">))</span> <span class="o">+</span> <span class="s1">&#39; tensor inputs.&#39;</span><span class="p">)</span>

        <span class="n">cache_key</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">input_shapes</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">cache_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape_cache</span><span class="p">:</span>
            <span class="n">output_shapes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_shapes</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_shapes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">output_shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">output_shapes</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Bad luck, we have to run the graph manually.</span>
            <span class="n">layers_to_output_shapes</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_shapes</span><span class="p">)):</span>
                <span class="n">layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">input_shape</span> <span class="o">=</span> <span class="n">input_shapes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="c1"># It&#39;s an input layer: compute_output_shape is identity,</span>
                <span class="c1"># and there is only one node and one tensor output.</span>
                <span class="n">shape_key</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;_0_0&#39;</span>
                <span class="n">layers_to_output_shapes</span><span class="p">[</span><span class="n">shape_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_shape</span>

            <span class="n">depth_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes_by_depth</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="n">depth_keys</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="c1"># Iterate over nodes, by depth level.</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">depth_keys</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">depth</span> <span class="ow">in</span> <span class="n">depth_keys</span><span class="p">:</span>
                    <span class="n">nodes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes_by_depth</span><span class="p">[</span><span class="n">depth</span><span class="p">]</span>
                    <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">:</span>
                        <span class="c1"># This is always a single layer, never a list.</span>
                        <span class="n">layer</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">outbound_layer</span>
                        <span class="k">if</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_layers</span><span class="p">:</span>
                            <span class="c1"># We&#39;ve already covered the input layers</span>
                            <span class="c1"># a few lines above.</span>
                            <span class="k">continue</span>
                        <span class="c1"># Potentially redundant list,</span>
                        <span class="c1"># same size of node.input_tensors.</span>
                        <span class="n">input_shapes</span> <span class="o">=</span> <span class="p">[]</span>
                        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">inbound_layers</span><span class="p">)):</span>
                            <span class="n">inbound_layer</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">inbound_layers</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                            <span class="n">node_index</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">node_indices</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                            <span class="n">tensor_index</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">tensor_indices</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
                            <span class="n">shape_key</span> <span class="o">=</span> <span class="n">inbound_layer</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;_</span><span class="si">%s</span><span class="s1">_</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">node_index</span><span class="p">,</span> <span class="n">tensor_index</span><span class="p">)</span>
                            <span class="n">input_shape</span> <span class="o">=</span> <span class="n">layers_to_output_shapes</span><span class="p">[</span><span class="n">shape_key</span><span class="p">]</span>
                            <span class="n">input_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span>

                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_shapes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                            <span class="n">output_shape</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">compute_output_shape</span><span class="p">(</span><span class="n">input_shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">output_shape</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">compute_output_shape</span><span class="p">(</span><span class="n">input_shapes</span><span class="p">)</span>

                        <span class="n">output_shapes</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>
                        <span class="n">node_index</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">node</span><span class="p">)</span>
                        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">output_shapes</span><span class="p">)):</span>
                            <span class="n">shape_key</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;_</span><span class="si">%s</span><span class="s1">_</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">node_index</span><span class="p">,</span> <span class="n">j</span><span class="p">)</span>
                            <span class="n">layers_to_output_shapes</span><span class="p">[</span><span class="n">shape_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_shapes</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>

            <span class="c1"># Read final output shapes from layers_to_output_shapes.</span>
            <span class="n">output_shapes</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">output_shape_keys</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_layers</span><span class="p">)):</span>
                <span class="n">layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">node_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layers_node_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">tensor_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layers_tensor_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">shape_key</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;_</span><span class="si">%s</span><span class="s1">_</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">node_index</span><span class="p">,</span> <span class="n">tensor_index</span><span class="p">)</span>
                <span class="n">output_shape_keys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shape_key</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">output_shape_keys</span><span class="p">):</span>
                <span class="k">assert</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">layers_to_output_shapes</span>
                <span class="n">output_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layers_to_output_shapes</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>
            <span class="c1"># Store in cache.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_shapes</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">output_shapes</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_shapes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">output_shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">return</span> <span class="n">output_shapes</span>

    <span class="k">def</span> <span class="nf">run_internal_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">masks</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Computes output tensors for new inputs.</span>

<span class="sd">        # Note:</span>
<span class="sd">            - Expects `inputs` to be a list (potentially with 1 element).</span>
<span class="sd">            - Can be run on non-Keras tensors.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            inputs: List of tensors</span>
<span class="sd">            masks: List of masks (tensors or None).</span>

<span class="sd">        # Returns</span>
<span class="sd">            Three lists: output_tensors, output_masks, output_shapes</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">masks</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">masks</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inputs</span><span class="p">))]</span>

        <span class="c1"># Dictionary mapping reference tensors to tuples</span>
        <span class="c1"># (computed tensor, compute mask)</span>
        <span class="c1"># we assume a 1:1 mapping from tensor to mask</span>
        <span class="c1"># TODO: raise exception when a `.compute_mask()` call</span>
        <span class="c1"># does not return a list the same size as `call`</span>
        <span class="n">tensor_map</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">mask</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">inputs</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">masks</span><span class="p">):</span>
            <span class="n">tensor_map</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">x</span><span class="p">))]</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>

        <span class="n">depth_keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nodes_by_depth</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">depth_keys</span><span class="o">.</span><span class="n">sort</span><span class="p">(</span><span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">depth</span> <span class="ow">in</span> <span class="n">depth_keys</span><span class="p">:</span>
            <span class="n">nodes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">nodes_by_depth</span><span class="p">[</span><span class="n">depth</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">nodes</span><span class="p">:</span>
                <span class="c1"># This is always a single layer, never a list.</span>
                <span class="n">layer</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">outbound_layer</span>

                <span class="n">reference_input_tensors</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">input_tensors</span>
                <span class="n">reference_output_tensors</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">output_tensors</span>

                <span class="c1"># If all previous input tensors are available in tensor_map,</span>
                <span class="c1"># then call node.inbound_layer on them.</span>
                <span class="n">computed_data</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># List of tuples (input, mask).</span>
                <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">reference_input_tensors</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="ow">in</span> <span class="n">tensor_map</span><span class="p">:</span>
                        <span class="n">computed_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tensor_map</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">x</span><span class="p">))])</span>

                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">computed_data</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">reference_input_tensors</span><span class="p">):</span>
                    <span class="c1"># call layer</span>
                    <span class="k">with</span> <span class="n">K</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">):</span>
                        <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">arguments</span><span class="p">:</span>
                            <span class="n">kwargs</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">arguments</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">computed_data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                            <span class="n">computed_tensor</span><span class="p">,</span> <span class="n">computed_mask</span> <span class="o">=</span> <span class="n">computed_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                            <span class="k">if</span> <span class="n">has_arg</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">call</span><span class="p">,</span> <span class="s1">&#39;mask&#39;</span><span class="p">):</span>
                                <span class="k">if</span> <span class="s1">&#39;mask&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                                    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;mask&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">computed_mask</span>
                            <span class="n">output_tensors</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">computed_tensor</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
                            <span class="n">output_masks</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">compute_mask</span><span class="p">(</span><span class="n">computed_tensor</span><span class="p">,</span>
                                                                       <span class="n">computed_mask</span><span class="p">))</span>
                            <span class="n">computed_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">computed_tensor</span><span class="p">]</span>
                            <span class="n">computed_masks</span> <span class="o">=</span> <span class="p">[</span><span class="n">computed_mask</span><span class="p">]</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">computed_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">computed_data</span><span class="p">]</span>
                            <span class="n">computed_masks</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">computed_data</span><span class="p">]</span>
                            <span class="k">if</span> <span class="n">has_arg</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">call</span><span class="p">,</span> <span class="s1">&#39;mask&#39;</span><span class="p">):</span>
                                <span class="k">if</span> <span class="s1">&#39;mask&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="p">:</span>
                                    <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;mask&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">computed_masks</span>
                            <span class="n">output_tensors</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">computed_tensors</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
                            <span class="n">output_masks</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">compute_mask</span><span class="p">(</span><span class="n">computed_tensors</span><span class="p">,</span>
                                                                       <span class="n">computed_masks</span><span class="p">))</span>

                        <span class="c1"># Apply activity regularizer if any:</span>
                        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;activity_regularizer&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">layer</span><span class="o">.</span><span class="n">activity_regularizer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="n">regularization_losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">layer</span><span class="o">.</span><span class="n">activity_regularizer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">computed_tensors</span><span class="p">]</span>
                            <span class="n">layer</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="n">regularization_losses</span><span class="p">,</span> <span class="n">computed_tensors</span><span class="p">)</span>

                    <span class="c1"># Update model updates and losses:</span>
                    <span class="c1"># Keep track of updates that depend on the inputs</span>
                    <span class="c1"># (e.g. BN updates).</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">add_update</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">get_updates_for</span><span class="p">(</span><span class="n">computed_tensors</span><span class="p">),</span> <span class="n">inputs</span><span class="p">)</span>
                    <span class="c1"># Keep track of unconditional updates (e.g. a counter).</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">add_update</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">get_updates_for</span><span class="p">(</span><span class="kc">None</span><span class="p">),</span> <span class="kc">None</span><span class="p">)</span>
                    <span class="c1"># Keep track of losses that depend on the inputs</span>
                    <span class="c1"># (e.g. activity regularizers).</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">get_losses_for</span><span class="p">(</span><span class="n">computed_tensors</span><span class="p">),</span> <span class="n">inputs</span><span class="p">)</span>
                    <span class="c1"># Keep track of unconditional losses</span>
                    <span class="c1"># (e.g. weight regularizers).</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">add_loss</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">get_losses_for</span><span class="p">(</span><span class="kc">None</span><span class="p">),</span> <span class="kc">None</span><span class="p">)</span>

                    <span class="c1"># Update _keras_shape.</span>
                    <span class="k">if</span> <span class="nb">all</span><span class="p">([</span><span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;_keras_shape&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">computed_tensors</span><span class="p">]):</span>
                        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">computed_tensors</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                            <span class="n">shapes</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">compute_output_shape</span><span class="p">(</span><span class="n">computed_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_keras_shape</span><span class="p">))</span>
                            <span class="n">uses_learning_phase</span> <span class="o">=</span> <span class="n">computed_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">_uses_learning_phase</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="n">shapes</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">compute_output_shape</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">_keras_shape</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">computed_tensors</span><span class="p">]))</span>
                            <span class="n">uses_learning_phase</span> <span class="o">=</span> <span class="nb">any</span><span class="p">([</span><span class="n">x</span><span class="o">.</span><span class="n">_uses_learning_phase</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">computed_tensors</span><span class="p">])</span>
                        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">output_tensors</span><span class="p">,</span> <span class="n">shapes</span><span class="p">):</span>
                            <span class="n">x</span><span class="o">.</span><span class="n">_keras_shape</span> <span class="o">=</span> <span class="n">s</span>
                            <span class="n">x</span><span class="o">.</span><span class="n">_uses_learning_phase</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;_uses_learning_phase&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span> <span class="ow">or</span> <span class="n">uses_learning_phase</span>

                    <span class="c1"># Update tensor_map.</span>
                    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">mask</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">reference_output_tensors</span><span class="p">,</span> <span class="n">output_tensors</span><span class="p">,</span> <span class="n">output_masks</span><span class="p">):</span>
                        <span class="n">tensor_map</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">x</span><span class="p">))]</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>

        <span class="n">output_tensors</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">output_masks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">output_shapes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="p">:</span>
            <span class="k">assert</span> <span class="nb">str</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="ow">in</span> <span class="n">tensor_map</span><span class="p">,</span> <span class="s1">&#39;Could not compute output &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">tensor</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">tensor_map</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">x</span><span class="p">))]</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="s1">&#39;_keras_shape&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">output_shapes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">shape</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">_keras_shape</span>
                <span class="n">output_shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">output_shapes</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="n">output_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tensor</span><span class="p">)</span>
            <span class="n">output_masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>

        <span class="c1"># Update cache;</span>
        <span class="c1"># keys are based on ids on input tensors and inputs masks.</span>
        <span class="n">cache_key</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">])</span>
        <span class="n">cache_key</span> <span class="o">+=</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">masks</span><span class="p">])</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_tensors</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">output_tensors</span> <span class="o">=</span> <span class="n">output_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_output_tensor_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_tensors</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_output_tensor_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_tensors</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_masks</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">output_masks</span> <span class="o">=</span> <span class="n">output_masks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_output_mask_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_masks</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_output_mask_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_masks</span>

        <span class="k">if</span> <span class="n">output_shapes</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">input_shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">_keras_shape</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">]</span>
            <span class="n">cache_key</span> <span class="o">=</span> <span class="s1">&#39;,&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">input_shapes</span><span class="p">])</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">output_shapes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">output_shapes</span> <span class="o">=</span> <span class="n">output_shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_shapes</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_output_shape_cache</span><span class="p">[</span><span class="n">cache_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">output_shapes</span>
        <span class="k">return</span> <span class="n">output_tensors</span><span class="p">,</span> <span class="n">output_masks</span><span class="p">,</span> <span class="n">output_shapes</span>

    <span class="k">def</span> <span class="nf">get_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="c1"># Build a map from a layer unique name (self._node_key)</span>
        <span class="c1"># to the index of the nodes that are saved in the config.</span>
        <span class="c1"># Only nodes in container_nodes are saved.</span>
        <span class="n">node_conversion_map</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="p">,</span> <span class="n">Container</span><span class="p">):</span>
                <span class="c1"># Containers start with a pre-existing node</span>
                <span class="c1"># linking their input to output.</span>
                <span class="n">kept_nodes</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">kept_nodes</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">original_node_index</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">):</span>
                <span class="n">node_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node_key</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">original_node_index</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">node_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">container_nodes</span><span class="p">:</span>
                    <span class="c1"># i.e. we mark it to be saved</span>
                    <span class="n">node_conversion_map</span><span class="p">[</span><span class="n">node_key</span><span class="p">]</span> <span class="o">=</span> <span class="n">kept_nodes</span>
                    <span class="n">kept_nodes</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># serialize and save the layers in layer_configs</span>
        <span class="n">layer_configs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>  <span class="c1"># From the earliest layers on.</span>
            <span class="n">layer_class_name</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
            <span class="n">layer_config</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
            <span class="n">filtered_inbound_nodes</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">original_node_index</span><span class="p">,</span> <span class="n">node</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">):</span>
                <span class="n">node_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node_key</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">original_node_index</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">node_key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">container_nodes</span><span class="p">:</span>
                    <span class="c1"># The node is relevant to the model:</span>
                    <span class="c1"># add to filtered_inbound_nodes.</span>
                    <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">arguments</span><span class="p">:</span>
                        <span class="k">try</span><span class="p">:</span>
                            <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">arguments</span><span class="p">)</span>
                            <span class="n">kwargs</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">arguments</span>
                        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                                <span class="s1">&#39;Layer &#39;</span> <span class="o">+</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span>
                                <span class="s1">&#39; was passed non-serializable keyword arguments: &#39;</span> <span class="o">+</span>
                                <span class="nb">str</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">arguments</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;. They will not be included &#39;</span>
                                <span class="s1">&#39;in the serialized model (and thus will be missing &#39;</span>
                                <span class="s1">&#39;at deserialization time).&#39;</span><span class="p">)</span>
                            <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
                    <span class="k">if</span> <span class="n">node</span><span class="o">.</span><span class="n">inbound_layers</span><span class="p">:</span>
                        <span class="n">node_data</span> <span class="o">=</span> <span class="p">[]</span>
                        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">inbound_layers</span><span class="p">)):</span>
                            <span class="n">inbound_layer</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">inbound_layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                            <span class="n">node_index</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">node_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                            <span class="n">tensor_index</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">tensor_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

                            <span class="n">new_node_index</span> <span class="o">=</span> <span class="n">node_conversion_map</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">_node_key</span><span class="p">(</span><span class="n">inbound_layer</span><span class="p">,</span> <span class="n">node_index</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
                            <span class="n">node_data</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">inbound_layer</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                                              <span class="n">new_node_index</span><span class="p">,</span>
                                              <span class="n">tensor_index</span><span class="p">,</span>
                                              <span class="n">kwargs</span><span class="p">])</span>
                        <span class="n">filtered_inbound_nodes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_data</span><span class="p">)</span>
            <span class="n">layer_configs</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
                <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">,</span>
                <span class="s1">&#39;class_name&#39;</span><span class="p">:</span> <span class="n">layer_class_name</span><span class="p">,</span>
                <span class="s1">&#39;config&#39;</span><span class="p">:</span> <span class="n">layer_config</span><span class="p">,</span>
                <span class="s1">&#39;inbound_nodes&#39;</span><span class="p">:</span> <span class="n">filtered_inbound_nodes</span><span class="p">,</span>
            <span class="p">})</span>
        <span class="n">config</span><span class="p">[</span><span class="s1">&#39;layers&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">layer_configs</span>

        <span class="c1"># Gather info about inputs and outputs.</span>
        <span class="n">model_inputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_layers</span><span class="p">)):</span>
            <span class="n">layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">node_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_layers_node_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="n">node_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node_key</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">node_index</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">node_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">container_nodes</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">new_node_index</span> <span class="o">=</span> <span class="n">node_conversion_map</span><span class="p">[</span><span class="n">node_key</span><span class="p">]</span>
            <span class="n">tensor_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_layers_tensor_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">model_inputs</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">new_node_index</span><span class="p">,</span> <span class="n">tensor_index</span><span class="p">])</span>
        <span class="n">config</span><span class="p">[</span><span class="s1">&#39;input_layers&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_inputs</span>
        <span class="n">model_outputs</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_layers</span><span class="p">)):</span>
            <span class="n">layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">node_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layers_node_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="n">node_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_node_key</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">node_index</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">node_key</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">container_nodes</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">new_node_index</span> <span class="o">=</span> <span class="n">node_conversion_map</span><span class="p">[</span><span class="n">node_key</span><span class="p">]</span>
            <span class="n">tensor_index</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layers_tensor_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">model_outputs</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">new_node_index</span><span class="p">,</span> <span class="n">tensor_index</span><span class="p">])</span>
        <span class="n">config</span><span class="p">[</span><span class="s1">&#39;output_layers&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model_outputs</span>
        <span class="k">return</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_config</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">custom_objects</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Instantiates a Model from its config (output of `get_config()`).</span>

<span class="sd">        # Arguments</span>
<span class="sd">            config: Model config dictionary.</span>
<span class="sd">            custom_objects: Optional dictionary mapping names</span>
<span class="sd">                (strings) to custom classes or functions to be</span>
<span class="sd">                considered during deserialization.</span>

<span class="sd">        # Returns</span>
<span class="sd">            A model instance.</span>

<span class="sd">        # Raises</span>
<span class="sd">            ValueError: In case of improperly formatted config dict.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Layer instances created during</span>
        <span class="c1"># the graph reconstruction process</span>
        <span class="n">created_layers</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># Dictionary mapping layer instances to</span>
        <span class="c1"># node data that specifies a layer call.</span>
        <span class="c1"># It acts as a queue that maintains any unprocessed</span>
        <span class="c1"># layer call until it becomes possible to process it</span>
        <span class="c1"># (i.e. until the input tensors to the call all exist).</span>
        <span class="n">unprocessed_nodes</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">def</span> <span class="nf">add_unprocessed_node</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">node_data</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">layer</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">unprocessed_nodes</span><span class="p">:</span>
                <span class="n">unprocessed_nodes</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">node_data</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">unprocessed_nodes</span><span class="p">[</span><span class="n">layer</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">node_data</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">process_node</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">node_data</span><span class="p">):</span>
            <span class="n">input_tensors</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">input_data</span> <span class="ow">in</span> <span class="n">node_data</span><span class="p">:</span>
                <span class="n">inbound_layer_name</span> <span class="o">=</span> <span class="n">input_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">inbound_node_index</span> <span class="o">=</span> <span class="n">input_data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">inbound_tensor_index</span> <span class="o">=</span> <span class="n">input_data</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
                    <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
                    <span class="n">kwargs</span> <span class="o">=</span> <span class="n">input_data</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Improperly formatted model config.&#39;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">inbound_layer_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">created_layers</span><span class="p">:</span>
                    <span class="n">add_unprocessed_node</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">node_data</span><span class="p">)</span>
                    <span class="k">return</span>
                <span class="n">inbound_layer</span> <span class="o">=</span> <span class="n">created_layers</span><span class="p">[</span><span class="n">inbound_layer_name</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inbound_layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">inbound_node_index</span><span class="p">:</span>
                    <span class="n">add_unprocessed_node</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">node_data</span><span class="p">)</span>
                    <span class="k">return</span>
                <span class="n">inbound_node</span> <span class="o">=</span> <span class="n">inbound_layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">[</span><span class="n">inbound_node_index</span><span class="p">]</span>
                <span class="n">input_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inbound_node</span><span class="o">.</span><span class="n">output_tensors</span><span class="p">[</span><span class="n">inbound_tensor_index</span><span class="p">])</span>
            <span class="c1"># Call layer on its inputs, thus creating the node</span>
            <span class="c1"># and building the layer if needed.</span>
            <span class="k">if</span> <span class="n">input_tensors</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_tensors</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">layer</span><span class="p">(</span><span class="n">input_tensors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">layer</span><span class="p">(</span><span class="n">input_tensors</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">process_layer</span><span class="p">(</span><span class="n">layer_data</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Deserialize a layer, then call it on appropriate inputs.</span>

<span class="sd">            # Arguments</span>
<span class="sd">                layer_data: layer config dict.</span>

<span class="sd">            # Raises</span>
<span class="sd">                ValueError: In case of improperly formatted `layer_data` dict.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="n">layer_name</span> <span class="o">=</span> <span class="n">layer_data</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span>

            <span class="c1"># Instantiate layer.</span>
            <span class="kn">from</span> <span class="nn">..layers</span> <span class="k">import</span> <span class="n">deserialize</span> <span class="k">as</span> <span class="n">deserialize_layer</span>

            <span class="n">layer</span> <span class="o">=</span> <span class="n">deserialize_layer</span><span class="p">(</span><span class="n">layer_data</span><span class="p">,</span>
                                      <span class="n">custom_objects</span><span class="o">=</span><span class="n">custom_objects</span><span class="p">)</span>
            <span class="n">created_layers</span><span class="p">[</span><span class="n">layer_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">layer</span>

            <span class="c1"># Gather layer inputs.</span>
            <span class="n">inbound_nodes_data</span> <span class="o">=</span> <span class="n">layer_data</span><span class="p">[</span><span class="s1">&#39;inbound_nodes&#39;</span><span class="p">]</span>
            <span class="k">for</span> <span class="n">node_data</span> <span class="ow">in</span> <span class="n">inbound_nodes_data</span><span class="p">:</span>
                <span class="c1"># We don&#39;t process nodes (i.e. make layer calls)</span>
                <span class="c1"># on the fly because the inbound node may not yet exist,</span>
                <span class="c1"># in case of layer shared at different topological depths</span>
                <span class="c1"># (e.g. a model such as A(B(A(B(x)))))</span>
                <span class="n">add_unprocessed_node</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">node_data</span><span class="p">)</span>

        <span class="c1"># First, we create all layers and enqueue nodes to be processed</span>
        <span class="k">for</span> <span class="n">layer_data</span> <span class="ow">in</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;layers&#39;</span><span class="p">]:</span>
            <span class="n">process_layer</span><span class="p">(</span><span class="n">layer_data</span><span class="p">)</span>
        <span class="c1"># Then we process nodes in order of layer depth.</span>
        <span class="c1"># Nodes that cannot yet be processed (if the inbound node</span>
        <span class="c1"># does not yet exist) are re-enqueued, and the process</span>
        <span class="c1"># is repeated until all nodes are processed.</span>
        <span class="k">while</span> <span class="n">unprocessed_nodes</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">layer_data</span> <span class="ow">in</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;layers&#39;</span><span class="p">]:</span>
                <span class="n">layer</span> <span class="o">=</span> <span class="n">created_layers</span><span class="p">[</span><span class="n">layer_data</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]]</span>
                <span class="k">if</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">unprocessed_nodes</span><span class="p">:</span>
                    <span class="k">for</span> <span class="n">node_data</span> <span class="ow">in</span> <span class="n">unprocessed_nodes</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">layer</span><span class="p">):</span>
                        <span class="n">process_node</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">node_data</span><span class="p">)</span>

        <span class="n">name</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;name&#39;</span><span class="p">)</span>
        <span class="n">input_tensors</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">output_tensors</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">layer_data</span> <span class="ow">in</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;input_layers&#39;</span><span class="p">]:</span>
            <span class="n">layer_name</span><span class="p">,</span> <span class="n">node_index</span><span class="p">,</span> <span class="n">tensor_index</span> <span class="o">=</span> <span class="n">layer_data</span>
            <span class="k">assert</span> <span class="n">layer_name</span> <span class="ow">in</span> <span class="n">created_layers</span>
            <span class="n">layer</span> <span class="o">=</span> <span class="n">created_layers</span><span class="p">[</span><span class="n">layer_name</span><span class="p">]</span>
            <span class="n">layer_output_tensors</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">[</span><span class="n">node_index</span><span class="p">]</span><span class="o">.</span><span class="n">output_tensors</span>
            <span class="n">input_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer_output_tensors</span><span class="p">[</span><span class="n">tensor_index</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">layer_data</span> <span class="ow">in</span> <span class="n">config</span><span class="p">[</span><span class="s1">&#39;output_layers&#39;</span><span class="p">]:</span>
            <span class="n">layer_name</span><span class="p">,</span> <span class="n">node_index</span><span class="p">,</span> <span class="n">tensor_index</span> <span class="o">=</span> <span class="n">layer_data</span>
            <span class="k">assert</span> <span class="n">layer_name</span> <span class="ow">in</span> <span class="n">created_layers</span>
            <span class="n">layer</span> <span class="o">=</span> <span class="n">created_layers</span><span class="p">[</span><span class="n">layer_name</span><span class="p">]</span>
            <span class="n">layer_output_tensors</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">[</span><span class="n">node_index</span><span class="p">]</span><span class="o">.</span><span class="n">output_tensors</span>
            <span class="n">output_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer_output_tensors</span><span class="p">[</span><span class="n">tensor_index</span><span class="p">])</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">input_tensors</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">output_tensors</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">include_optimizer</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Save the model to a single HDF5 file.</span>

<span class="sd">        The savefile includes:</span>
<span class="sd">            - The model architecture, allowing to re-instantiate the model.</span>
<span class="sd">            - The model weights.</span>
<span class="sd">            - The state of the optimizer, allowing to resume training</span>
<span class="sd">                exactly where you left off.</span>

<span class="sd">        This allows you to save the entirety of the state of a model</span>
<span class="sd">        in a single file.</span>

<span class="sd">        Saved models can be reinstantiated via `keras.models.load_model`.</span>
<span class="sd">        The model returned by `load_model`</span>
<span class="sd">        is a compiled model ready to be used (unless the saved model</span>
<span class="sd">        was never compiled in the first place).</span>

<span class="sd">        # Arguments</span>
<span class="sd">            filepath: String, path to the file to save the weights to.</span>
<span class="sd">            overwrite: Whether to silently overwrite any existing file at the</span>
<span class="sd">                target location, or provide the user with a manual prompt.</span>
<span class="sd">            include_optimizer: If True, save optimizer&#39;s state together.</span>

<span class="sd">        # Example</span>

<span class="sd">        ```python</span>
<span class="sd">        from keras.models import load_model</span>

<span class="sd">        model.save(&#39;my_model.h5&#39;)  # creates a HDF5 file &#39;my_model.h5&#39;</span>
<span class="sd">        del model  # deletes the existing model</span>

<span class="sd">        # returns a compiled model</span>
<span class="sd">        # identical to the previous one</span>
<span class="sd">        model = load_model(&#39;my_model.h5&#39;)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">..models</span> <span class="k">import</span> <span class="n">save_model</span>
        <span class="n">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="p">,</span> <span class="n">include_optimizer</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">save_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filepath</span><span class="p">,</span> <span class="n">overwrite</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Dumps all layer weights to a HDF5 file.</span>

<span class="sd">        The weight file has:</span>
<span class="sd">            - `layer_names` (attribute), a list of strings</span>
<span class="sd">                (ordered names of model layers).</span>
<span class="sd">            - For every layer, a `group` named `layer.name`</span>
<span class="sd">                - For every such layer group, a group attribute `weight_names`,</span>
<span class="sd">                    a list of strings</span>
<span class="sd">                    (ordered names of weights tensor of the layer).</span>
<span class="sd">                - For every weight in the layer, a dataset</span>
<span class="sd">                    storing the weight value, named after the weight tensor.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            filepath: String, path to the file to save the weights to.</span>
<span class="sd">            overwrite: Whether to silently overwrite any existing file at the</span>
<span class="sd">                target location, or provide the user with a manual prompt.</span>

<span class="sd">        # Raises</span>
<span class="sd">            ImportError: If h5py is not available.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">h5py</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s1">&#39;`save_weights` requires h5py.&#39;</span><span class="p">)</span>
        <span class="c1"># If file exists and should not be overwritten:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">overwrite</span> <span class="ow">and</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">filepath</span><span class="p">):</span>
            <span class="n">proceed</span> <span class="o">=</span> <span class="n">ask_to_proceed_with_overwrite</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">proceed</span><span class="p">:</span>
                <span class="k">return</span>
        <span class="n">f</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span>
        <span class="n">save_weights_to_hdf5_group</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>
        <span class="n">f</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
        <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">load_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filepath</span><span class="p">,</span> <span class="n">by_name</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Loads all layer weights from a HDF5 save file.</span>

<span class="sd">        If `by_name` is False (default) weights are loaded</span>
<span class="sd">        based on the network&#39;s topology, meaning the architecture</span>
<span class="sd">        should be the same as when the weights were saved.</span>
<span class="sd">        Note that layers that don&#39;t have weights are not taken</span>
<span class="sd">        into account in the topological ordering, so adding or</span>
<span class="sd">        removing layers is fine as long as they don&#39;t have weights.</span>

<span class="sd">        If `by_name` is True, weights are loaded into layers</span>
<span class="sd">        only if they share the same name. This is useful</span>
<span class="sd">        for fine-tuning or transfer-learning models where</span>
<span class="sd">        some of the layers have changed.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            filepath: String, path to the weights file to load.</span>
<span class="sd">            by_name: Boolean, whether to load weights by name</span>
<span class="sd">                or by topological order.</span>

<span class="sd">        # Raises</span>
<span class="sd">            ImportError: If h5py is not available.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">h5py</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span><span class="s1">&#39;`load_weights` requires h5py.&#39;</span><span class="p">)</span>
        <span class="n">f</span> <span class="o">=</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="s1">&#39;layer_names&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">attrs</span> <span class="ow">and</span> <span class="s1">&#39;model_weights&#39;</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">f</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="s1">&#39;model_weights&#39;</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">by_name</span><span class="p">:</span>
            <span class="n">load_weights_from_hdf5_group_by_name</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">load_weights_from_hdf5_group</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="s1">&#39;close&#39;</span><span class="p">):</span>
            <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_updated_config</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Util hared between different serialization methods.</span>

<span class="sd">        # Returns</span>
<span class="sd">            Model config with Keras version information added.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">..</span> <span class="k">import</span> <span class="n">__version__</span> <span class="k">as</span> <span class="n">keras_version</span>

        <span class="n">config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
        <span class="n">model_config</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;class_name&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
            <span class="s1">&#39;config&#39;</span><span class="p">:</span> <span class="n">config</span><span class="p">,</span>
            <span class="s1">&#39;keras_version&#39;</span><span class="p">:</span> <span class="n">keras_version</span><span class="p">,</span>
            <span class="s1">&#39;backend&#39;</span><span class="p">:</span> <span class="n">K</span><span class="o">.</span><span class="n">backend</span><span class="p">()</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="n">model_config</span>

    <span class="k">def</span> <span class="nf">to_json</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a JSON string containing the network configuration.</span>

<span class="sd">        To load a network from a JSON save file, use</span>
<span class="sd">        `keras.models.model_from_json(json_string, custom_objects={})`.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            **kwargs: Additional keyword arguments</span>
<span class="sd">                to be passed to `json.dumps()`.</span>

<span class="sd">        # Returns</span>
<span class="sd">            A JSON string.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">def</span> <span class="nf">get_json_type</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
            <span class="c1"># If obj is any numpy type</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span><span class="o">.</span><span class="vm">__module__</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="vm">__name__</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">obj</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

            <span class="c1"># If obj is a python &#39;type&#39;</span>
            <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="nb">type</span><span class="o">.</span><span class="vm">__name__</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">obj</span><span class="o">.</span><span class="vm">__name__</span>

            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s1">&#39;Not JSON Serializable:&#39;</span><span class="p">,</span> <span class="n">obj</span><span class="p">)</span>

        <span class="n">model_config</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_updated_config</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">model_config</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="n">get_json_type</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">to_yaml</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Returns a yaml string containing the network configuration.</span>

<span class="sd">        To load a network from a yaml save file, use</span>
<span class="sd">        `keras.models.model_from_yaml(yaml_string, custom_objects={})`.</span>

<span class="sd">        `custom_objects` should be a dictionary mapping</span>
<span class="sd">        the names of custom losses / layers / etc to the corresponding</span>
<span class="sd">        functions / classes.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            **kwargs: Additional keyword arguments</span>
<span class="sd">                to be passed to `yaml.dump()`.</span>

<span class="sd">        # Returns</span>
<span class="sd">            A YAML string.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">yaml</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_updated_config</span><span class="p">(),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">summary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">line_length</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">positions</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">print_fn</span><span class="o">=</span><span class="nb">print</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Prints a string summary of the network.</span>

<span class="sd">        # Arguments</span>
<span class="sd">            line_length: Total length of printed lines</span>
<span class="sd">                (e.g. set this to adapt the display to different</span>
<span class="sd">                terminal window sizes).</span>
<span class="sd">            positions: Relative or absolute positions of log elements</span>
<span class="sd">                in each line. If not provided,</span>
<span class="sd">                defaults to `[.33, .55, .67, 1.]`.</span>
<span class="sd">            print_fn: Print function to use.</span>
<span class="sd">                It will be called on each line of the summary.</span>
<span class="sd">                You can set it to a custom function</span>
<span class="sd">                in order to capture the string summary.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">print_layer_summary</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                                   <span class="n">line_length</span><span class="o">=</span><span class="n">line_length</span><span class="p">,</span>
                                   <span class="n">positions</span><span class="o">=</span><span class="n">positions</span><span class="p">,</span>
                                   <span class="n">print_fn</span><span class="o">=</span><span class="n">print_fn</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_source_inputs</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">layer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">node_index</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Returns the list of input tensors necessary to compute `tensor`.</span>

<span class="sd">    Output will always be a list of tensors</span>
<span class="sd">    (potentially with 1 element).</span>

<span class="sd">    # Arguments</span>
<span class="sd">        tensor: The tensor to start from.</span>
<span class="sd">        layer: Origin layer of the tensor. Will be</span>
<span class="sd">            determined via tensor._keras_history if not provided.</span>
<span class="sd">        node_index: Origin node index of the tensor.</span>

<span class="sd">    # Returns</span>
<span class="sd">        List of input tensors.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="s1">&#39;_keras_history&#39;</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">tensor</span>

    <span class="k">if</span> <span class="n">layer</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">node_index</span><span class="p">:</span>
        <span class="n">layer</span><span class="p">,</span> <span class="n">node_index</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tensor</span><span class="o">.</span><span class="n">_keras_history</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">tensor</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">node</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">[</span><span class="n">node_index</span><span class="p">]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">node</span><span class="o">.</span><span class="n">inbound_layers</span><span class="p">:</span>
            <span class="c1"># Reached an Input layer, stop recursion.</span>
            <span class="k">return</span> <span class="n">node</span><span class="o">.</span><span class="n">input_tensors</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">source_tensors</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">node</span><span class="o">.</span><span class="n">inbound_layers</span><span class="p">)):</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">input_tensors</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">layer</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">inbound_layers</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">node_index</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">node_indices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">previous_sources</span> <span class="o">=</span> <span class="n">get_source_inputs</span><span class="p">(</span><span class="n">x</span><span class="p">,</span>
                                                     <span class="n">layer</span><span class="p">,</span>
                                                     <span class="n">node_index</span><span class="p">)</span>
                <span class="c1"># Avoid input redundancy.</span>
                <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">previous_sources</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">x</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">source_tensors</span><span class="p">:</span>
                        <span class="n">source_tensors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">source_tensors</span>


<span class="k">def</span> <span class="nf">_to_list</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Normalizes a list/tensor into a list.</span>

<span class="sd">    If a tensor is passed, we return</span>
<span class="sd">    a list of size 1 containing the tensor.</span>

<span class="sd">    # Arguments</span>
<span class="sd">        x: target object to be normalized.</span>

<span class="sd">    # Returns</span>
<span class="sd">        A list.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">x</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">_object_list_uid</span><span class="p">(</span><span class="n">object_list</span><span class="p">):</span>
    <span class="n">object_list</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">object_list</span><span class="p">)</span>
    <span class="k">return</span> <span class="s1">&#39;, &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="nb">id</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">object_list</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">_is_all_none</span><span class="p">(</span><span class="n">iterable_or_element</span><span class="p">):</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">iterable_or_element</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
        <span class="n">iterable</span> <span class="o">=</span> <span class="p">[</span><span class="n">iterable_or_element</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">iterable</span> <span class="o">=</span> <span class="n">iterable_or_element</span>
    <span class="k">for</span> <span class="n">element</span> <span class="ow">in</span> <span class="n">iterable</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">element</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="kc">True</span>


<span class="k">def</span> <span class="nf">_collect_previous_mask</span><span class="p">(</span><span class="n">input_tensors</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Retrieves the output mask(s) of the previous node.</span>

<span class="sd">    # Arguments</span>
<span class="sd">        input_tensors: A tensor or list of tensors.</span>

<span class="sd">    # Returns</span>
<span class="sd">        A mask tensor or list of mask tensors.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">input_tensors</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">input_tensors</span><span class="p">)</span>
    <span class="n">masks</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">input_tensors</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;_keras_history&#39;</span><span class="p">):</span>
            <span class="n">inbound_layer</span><span class="p">,</span> <span class="n">node_index</span><span class="p">,</span> <span class="n">tensor_index</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">_keras_history</span>
            <span class="n">node</span> <span class="o">=</span> <span class="n">inbound_layer</span><span class="o">.</span><span class="n">inbound_nodes</span><span class="p">[</span><span class="n">node_index</span><span class="p">]</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">node</span><span class="o">.</span><span class="n">output_masks</span><span class="p">[</span><span class="n">tensor_index</span><span class="p">]</span>
            <span class="n">masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">masks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">masks</span>


<span class="k">def</span> <span class="nf">_to_snake_case</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">intermediate</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;(.)([A-Z][a-z0-9]+)&#39;</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;\1_\2&#39;</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
    <span class="n">insecure</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;([a-z])([A-Z])&#39;</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;\1_\2&#39;</span><span class="p">,</span> <span class="n">intermediate</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
    <span class="c1"># If the class is private the name starts with &quot;_&quot; which is not secure</span>
    <span class="c1"># for creating scopes. We prefix the name with &quot;private&quot; in this case.</span>
    <span class="k">if</span> <span class="n">insecure</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;_&#39;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">insecure</span>
    <span class="k">return</span> <span class="s1">&#39;private&#39;</span> <span class="o">+</span> <span class="n">insecure</span>


<span class="k">def</span> <span class="nf">_collect_input_shape</span><span class="p">(</span><span class="n">input_tensors</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Collects the output shape(s) of a list of Keras tensors.</span>

<span class="sd">    # Arguments</span>
<span class="sd">        input_tensors: list of input tensors (or single input tensor).</span>

<span class="sd">    # Returns</span>
<span class="sd">        List of shape tuples (or single tuple), one tuple per input.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">input_tensors</span> <span class="o">=</span> <span class="n">_to_list</span><span class="p">(</span><span class="n">input_tensors</span><span class="p">)</span>
    <span class="n">shapes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">input_tensors</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">K</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
            <span class="n">shapes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shapes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">shapes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">shapes</span>


<span class="k">def</span> <span class="nf">save_weights_to_hdf5_group</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">layers</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">..</span> <span class="k">import</span> <span class="n">__version__</span> <span class="k">as</span> <span class="n">keras_version</span>

    <span class="n">f</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;layer_names&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf8&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">]</span>
    <span class="n">f</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;backend&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">backend</span><span class="p">()</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf8&#39;</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;keras_version&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">keras_version</span><span class="p">)</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf8&#39;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">:</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">create_group</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="n">symbolic_weights</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">weights</span>
        <span class="n">weight_values</span> <span class="o">=</span> <span class="n">K</span><span class="o">.</span><span class="n">batch_get_value</span><span class="p">(</span><span class="n">symbolic_weights</span><span class="p">)</span>
        <span class="n">weight_names</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">symbolic_weights</span><span class="p">,</span> <span class="n">weight_values</span><span class="p">)):</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="s1">&#39;name&#39;</span><span class="p">)</span> <span class="ow">and</span> <span class="n">w</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
                <span class="n">name</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;param_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">weight_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf8&#39;</span><span class="p">))</span>
        <span class="n">g</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;weight_names&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">weight_names</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">weight_names</span><span class="p">,</span> <span class="n">weight_values</span><span class="p">):</span>
            <span class="n">param_dset</span> <span class="o">=</span> <span class="n">g</span><span class="o">.</span><span class="n">create_dataset</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">val</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
                                          <span class="n">dtype</span><span class="o">=</span><span class="n">val</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">val</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="c1"># scalar</span>
                <span class="n">param_dset</span><span class="p">[()]</span> <span class="o">=</span> <span class="n">val</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">param_dset</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">val</span>


<span class="k">def</span> <span class="nf">preprocess_weights_for_loading</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span>
                                   <span class="n">original_keras_version</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                   <span class="n">original_backend</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Converts layers weights from Keras 1 format to Keras 2.</span>

<span class="sd">    # Arguments</span>
<span class="sd">        layer: Layer instance.</span>
<span class="sd">        weights: List of weights values (Numpy arrays).</span>
<span class="sd">        original_keras_version: Keras version for the weights, as a string.</span>
<span class="sd">        original_backend: Keras backend the weights were trained with,</span>
<span class="sd">            as a string.</span>

<span class="sd">    # Returns</span>
<span class="sd">        A list of weights values (Numpy arrays).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">original_keras_version</span> <span class="o">==</span> <span class="s1">&#39;1&#39;</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;Bidirectional&#39;</span><span class="p">:</span>
            <span class="n">num_weights_per_layer</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>

            <span class="n">forward_weights</span> <span class="o">=</span> <span class="n">preprocess_weights_for_loading</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">forward_layer</span><span class="p">,</span>
                                                             <span class="n">weights</span><span class="p">[:</span><span class="n">num_weights_per_layer</span><span class="p">],</span>
                                                             <span class="n">original_keras_version</span><span class="p">,</span>
                                                             <span class="n">original_backend</span><span class="p">)</span>
            <span class="n">backward_weights</span> <span class="o">=</span> <span class="n">preprocess_weights_for_loading</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">backward_layer</span><span class="p">,</span>
                                                              <span class="n">weights</span><span class="p">[</span><span class="n">num_weights_per_layer</span><span class="p">:],</span>
                                                              <span class="n">original_keras_version</span><span class="p">,</span>
                                                              <span class="n">original_backend</span><span class="p">)</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">forward_weights</span> <span class="o">+</span> <span class="n">backward_weights</span>

        <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;TimeDistributed&#39;</span><span class="p">:</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">preprocess_weights_for_loading</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">layer</span><span class="p">,</span>
                                                     <span class="n">weights</span><span class="p">,</span>
                                                     <span class="n">original_keras_version</span><span class="p">,</span>
                                                     <span class="n">original_backend</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;Conv1D&#39;</span><span class="p">:</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
            <span class="c1"># Handle Keras 1.1 format</span>
            <span class="k">if</span> <span class="n">shape</span><span class="p">[:</span><span class="mi">2</span><span class="p">]</span> <span class="o">!=</span> <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">!=</span> <span class="n">layer</span><span class="o">.</span><span class="n">filters</span><span class="p">:</span>
                <span class="c1"># Legacy shape:</span>
                <span class="c1"># (filters, input_dim, filter_length, 1)</span>
                <span class="k">assert</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">layer</span><span class="o">.</span><span class="n">filters</span> <span class="ow">and</span> <span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]</span> <span class="o">==</span> <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
            <span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">][:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>

        <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;Conv2D&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">data_format</span> <span class="o">==</span> <span class="s1">&#39;channels_first&#39;</span><span class="p">:</span>
                <span class="c1"># old: (filters, stack_size, kernel_rows, kernel_cols)</span>
                <span class="c1"># new: (kernel_rows, kernel_cols, stack_size, filters)</span>
                <span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;Conv2DTranspose&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">data_format</span> <span class="o">==</span> <span class="s1">&#39;channels_last&#39;</span><span class="p">:</span>
                <span class="c1"># old: (kernel_rows, kernel_cols, stack_size, filters)</span>
                <span class="c1"># new: (kernel_rows, kernel_cols, filters, stack_size)</span>
                <span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">data_format</span> <span class="o">==</span> <span class="s1">&#39;channels_first&#39;</span><span class="p">:</span>
                <span class="c1"># old: (filters, stack_size, kernel_rows, kernel_cols)</span>
                <span class="c1"># new: (kernel_rows, kernel_cols, filters, stack_size)</span>
                <span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;Conv3D&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">data_format</span> <span class="o">==</span> <span class="s1">&#39;channels_first&#39;</span><span class="p">:</span>
                <span class="c1"># old: (filters, stack_size, ...)</span>
                <span class="c1"># new: (..., stack_size, filters)</span>
                <span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;GRU&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">==</span> <span class="mi">9</span><span class="p">:</span>
                <span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                         <span class="n">weights</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
                                         <span class="n">weights</span><span class="p">[</span><span class="mi">6</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">recurrent_kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                                   <span class="n">weights</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span>
                                                   <span class="n">weights</span><span class="p">[</span><span class="mi">7</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">weights</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                                       <span class="n">weights</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span>
                                       <span class="n">weights</span><span class="p">[</span><span class="mi">8</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">kernel</span><span class="p">,</span> <span class="n">recurrent_kernel</span><span class="p">,</span> <span class="n">bias</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;LSTM&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">==</span> <span class="mi">12</span><span class="p">:</span>
                <span class="c1"># old: i, c, f, o</span>
                <span class="c1"># new: i, f, c, o</span>
                <span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                         <span class="n">weights</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span>
                                         <span class="n">weights</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
                                         <span class="n">weights</span><span class="p">[</span><span class="mi">9</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">recurrent_kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                                   <span class="n">weights</span><span class="p">[</span><span class="mi">7</span><span class="p">],</span>
                                                   <span class="n">weights</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span>
                                                   <span class="n">weights</span><span class="p">[</span><span class="mi">10</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">weights</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                                       <span class="n">weights</span><span class="p">[</span><span class="mi">8</span><span class="p">],</span>
                                       <span class="n">weights</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span>
                                       <span class="n">weights</span><span class="p">[</span><span class="mi">11</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">kernel</span><span class="p">,</span> <span class="n">recurrent_kernel</span><span class="p">,</span> <span class="n">bias</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;ConvLSTM2D&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">==</span> <span class="mi">12</span><span class="p">:</span>
                <span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                         <span class="n">weights</span><span class="p">[</span><span class="mi">6</span><span class="p">],</span>
                                         <span class="n">weights</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
                                         <span class="n">weights</span><span class="p">[</span><span class="mi">9</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">recurrent_kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                                   <span class="n">weights</span><span class="p">[</span><span class="mi">7</span><span class="p">],</span>
                                                   <span class="n">weights</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span>
                                                   <span class="n">weights</span><span class="p">[</span><span class="mi">10</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">weights</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                                       <span class="n">weights</span><span class="p">[</span><span class="mi">8</span><span class="p">],</span>
                                       <span class="n">weights</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span>
                                       <span class="n">weights</span><span class="p">[</span><span class="mi">11</span><span class="p">]],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">data_format</span> <span class="o">==</span> <span class="s1">&#39;channels_first&#39;</span><span class="p">:</span>
                    <span class="c1"># old: (filters, stack_size, kernel_rows, kernel_cols)</span>
                    <span class="c1"># new: (kernel_rows, kernel_cols, stack_size, filters)</span>
                    <span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
                    <span class="n">recurrent_kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">recurrent_kernel</span><span class="p">,</span>
                                                    <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
                <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">kernel</span><span class="p">,</span> <span class="n">recurrent_kernel</span><span class="p">,</span> <span class="n">bias</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;Model&#39;</span><span class="p">,</span> <span class="s1">&#39;Sequential&#39;</span><span class="p">]:</span>
            <span class="n">new_weights</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="c1"># trainable weights</span>
            <span class="k">for</span> <span class="n">sublayer</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
                <span class="n">num_weights</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">sublayer</span><span class="o">.</span><span class="n">trainable_weights</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">num_weights</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">new_weights</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">preprocess_weights_for_loading</span><span class="p">(</span>
                        <span class="n">layer</span><span class="o">=</span><span class="n">sublayer</span><span class="p">,</span>
                        <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">[:</span><span class="n">num_weights</span><span class="p">],</span>
                        <span class="n">original_keras_version</span><span class="o">=</span><span class="n">original_keras_version</span><span class="p">,</span>
                        <span class="n">original_backend</span><span class="o">=</span><span class="n">original_backend</span><span class="p">))</span>
                    <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">num_weights</span><span class="p">:]</span>

            <span class="c1"># non-trainable weights</span>
            <span class="k">for</span> <span class="n">sublayer</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
                <span class="n">num_weights</span> <span class="o">=</span> <span class="nb">len</span><span class="p">([</span><span class="n">l</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">sublayer</span><span class="o">.</span><span class="n">weights</span> <span class="k">if</span> <span class="n">l</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">sublayer</span><span class="o">.</span><span class="n">trainable_weights</span><span class="p">])</span>
                <span class="k">if</span> <span class="n">num_weights</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">new_weights</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">preprocess_weights_for_loading</span><span class="p">(</span>
                        <span class="n">layer</span><span class="o">=</span><span class="n">sublayer</span><span class="p">,</span>
                        <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">[:</span><span class="n">num_weights</span><span class="p">],</span>
                        <span class="n">original_keras_version</span><span class="o">=</span><span class="n">original_keras_version</span><span class="p">,</span>
                        <span class="n">original_backend</span><span class="o">=</span><span class="n">original_backend</span><span class="p">))</span>
                    <span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">num_weights</span><span class="p">:]</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="n">new_weights</span>

    <span class="n">conv_layers</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Conv1D&#39;</span><span class="p">,</span>
                   <span class="s1">&#39;Conv2D&#39;</span><span class="p">,</span>
                   <span class="s1">&#39;Conv3D&#39;</span><span class="p">,</span>
                   <span class="s1">&#39;Conv2DTranspose&#39;</span><span class="p">,</span>
                   <span class="s1">&#39;ConvLSTM2D&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="ow">in</span> <span class="n">conv_layers</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">original_backend</span> <span class="ow">and</span> <span class="n">K</span><span class="o">.</span><span class="n">backend</span><span class="p">()</span> <span class="o">!=</span> <span class="n">original_backend</span><span class="p">:</span>
            <span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_utils</span><span class="o">.</span><span class="n">convert_kernel</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;ConvLSTM2D&#39;</span><span class="p">:</span>
                <span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_utils</span><span class="o">.</span><span class="n">convert_kernel</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">K</span><span class="o">.</span><span class="n">int_shape</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">!=</span> <span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
            <span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">==</span> <span class="s1">&#39;ConvLSTM2D&#39;</span><span class="p">:</span>
                <span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">weights</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">weights</span>


<span class="k">def</span> <span class="nf">load_weights_from_hdf5_group</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">layers</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Implements topological (order-based) weight loading.</span>

<span class="sd">    # Arguments</span>
<span class="sd">        f: A pointer to a HDF5 group.</span>
<span class="sd">        layers: a list of target layers.</span>

<span class="sd">    # Raises</span>
<span class="sd">        ValueError: in case of mismatch between provided layers</span>
<span class="sd">            and weights file.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="s1">&#39;keras_version&#39;</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">attrs</span><span class="p">:</span>
        <span class="n">original_keras_version</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;keras_version&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf8&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">original_keras_version</span> <span class="o">=</span> <span class="s1">&#39;1&#39;</span>
    <span class="k">if</span> <span class="s1">&#39;backend&#39;</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">attrs</span><span class="p">:</span>
        <span class="n">original_backend</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;backend&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf8&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">original_backend</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">filtered_layers</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">weights</span>
        <span class="k">if</span> <span class="n">weights</span><span class="p">:</span>
            <span class="n">filtered_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>

    <span class="n">layer_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">n</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf8&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;layer_names&#39;</span><span class="p">]]</span>
    <span class="n">filtered_layer_names</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">layer_names</span><span class="p">:</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="n">weight_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">n</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf8&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;weight_names&#39;</span><span class="p">]]</span>
        <span class="k">if</span> <span class="n">weight_names</span><span class="p">:</span>
            <span class="n">filtered_layer_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="n">layer_names</span> <span class="o">=</span> <span class="n">filtered_layer_names</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layer_names</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">filtered_layers</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;You are trying to load a weight file &#39;</span>
                         <span class="s1">&#39;containing &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layer_names</span><span class="p">))</span> <span class="o">+</span>
                         <span class="s1">&#39; layers into a model with &#39;</span> <span class="o">+</span>
                         <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">filtered_layers</span><span class="p">))</span> <span class="o">+</span> <span class="s1">&#39; layers.&#39;</span><span class="p">)</span>

    <span class="c1"># We batch weight value assignments in a single backend call</span>
    <span class="c1"># which provides a speedup in TensorFlow.</span>
    <span class="n">weight_value_tuples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">layer_names</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="n">weight_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">n</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf8&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;weight_names&#39;</span><span class="p">]]</span>
        <span class="n">weight_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">g</span><span class="p">[</span><span class="n">weight_name</span><span class="p">]</span> <span class="k">for</span> <span class="n">weight_name</span> <span class="ow">in</span> <span class="n">weight_names</span><span class="p">]</span>
        <span class="n">layer</span> <span class="o">=</span> <span class="n">filtered_layers</span><span class="p">[</span><span class="n">k</span><span class="p">]</span>
        <span class="n">symbolic_weights</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">weights</span>
        <span class="n">weight_values</span> <span class="o">=</span> <span class="n">preprocess_weights_for_loading</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span>
                                                       <span class="n">weight_values</span><span class="p">,</span>
                                                       <span class="n">original_keras_version</span><span class="p">,</span>
                                                       <span class="n">original_backend</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">weight_values</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">symbolic_weights</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Layer #&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="o">+</span>
                             <span class="s1">&#39; (named &quot;&#39;</span> <span class="o">+</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span>
                             <span class="s1">&#39;&quot; in the current model) was found to &#39;</span>
                             <span class="s1">&#39;correspond to layer &#39;</span> <span class="o">+</span> <span class="n">name</span> <span class="o">+</span>
                             <span class="s1">&#39; in the save file. &#39;</span>
                             <span class="s1">&#39;However the new layer &#39;</span> <span class="o">+</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span>
                             <span class="s1">&#39; expects &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">symbolic_weights</span><span class="p">))</span> <span class="o">+</span>
                             <span class="s1">&#39; weights, but the saved weights have &#39;</span> <span class="o">+</span>
                             <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">weight_values</span><span class="p">))</span> <span class="o">+</span>
                             <span class="s1">&#39; elements.&#39;</span><span class="p">)</span>
        <span class="n">weight_value_tuples</span> <span class="o">+=</span> <span class="nb">zip</span><span class="p">(</span><span class="n">symbolic_weights</span><span class="p">,</span> <span class="n">weight_values</span><span class="p">)</span>
    <span class="n">K</span><span class="o">.</span><span class="n">batch_set_value</span><span class="p">(</span><span class="n">weight_value_tuples</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">load_weights_from_hdf5_group_by_name</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">layers</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Implements name-based weight loading.</span>

<span class="sd">    (instead of topological weight loading).</span>

<span class="sd">    Layers that have no matching name are skipped.</span>

<span class="sd">    # Arguments</span>
<span class="sd">        f: A pointer to a HDF5 group.</span>
<span class="sd">        layers: a list of target layers.</span>

<span class="sd">    # Raises</span>
<span class="sd">        ValueError: in case of mismatch between provided layers</span>
<span class="sd">            and weights file.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="s1">&#39;keras_version&#39;</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">attrs</span><span class="p">:</span>
        <span class="n">original_keras_version</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;keras_version&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf8&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">original_keras_version</span> <span class="o">=</span> <span class="s1">&#39;1&#39;</span>
    <span class="k">if</span> <span class="s1">&#39;backend&#39;</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">attrs</span><span class="p">:</span>
        <span class="n">original_backend</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;backend&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf8&#39;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">original_backend</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># New file format.</span>
    <span class="n">layer_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">n</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf8&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;layer_names&#39;</span><span class="p">]]</span>

    <span class="c1"># Reverse index of layer name to list of layers with name.</span>
    <span class="n">index</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">layers</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">:</span>
            <span class="n">index</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="p">[])</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>

    <span class="c1"># We batch weight value assignments in a single backend call</span>
    <span class="c1"># which provides a speedup in TensorFlow.</span>
    <span class="n">weight_value_tuples</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">layer_names</span><span class="p">):</span>
        <span class="n">g</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="n">weight_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">n</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf8&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s1">&#39;weight_names&#39;</span><span class="p">]]</span>
        <span class="n">weight_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">g</span><span class="p">[</span><span class="n">weight_name</span><span class="p">]</span> <span class="k">for</span> <span class="n">weight_name</span> <span class="ow">in</span> <span class="n">weight_names</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">index</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="p">[]):</span>
            <span class="n">symbolic_weights</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">weights</span>
            <span class="n">weight_values</span> <span class="o">=</span> <span class="n">preprocess_weights_for_loading</span><span class="p">(</span>
                <span class="n">layer</span><span class="p">,</span>
                <span class="n">weight_values</span><span class="p">,</span>
                <span class="n">original_keras_version</span><span class="p">,</span>
                <span class="n">original_backend</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">weight_values</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">symbolic_weights</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Layer #&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="o">+</span>
                                 <span class="s1">&#39; (named &quot;&#39;</span> <span class="o">+</span> <span class="n">layer</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span>
                                 <span class="s1">&#39;&quot;) expects &#39;</span> <span class="o">+</span>
                                 <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">symbolic_weights</span><span class="p">))</span> <span class="o">+</span>
                                 <span class="s1">&#39; weight(s), but the saved weights&#39;</span> <span class="o">+</span>
                                 <span class="s1">&#39; have &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">weight_values</span><span class="p">))</span> <span class="o">+</span>
                                 <span class="s1">&#39; element(s).&#39;</span><span class="p">)</span>
            <span class="c1"># Set values.</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">weight_values</span><span class="p">)):</span>
                <span class="n">weight_value_tuples</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">symbolic_weights</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                                            <span class="n">weight_values</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    <span class="n">K</span><span class="o">.</span><span class="n">batch_set_value</span><span class="p">(</span><span class="n">weight_value_tuples</span><span class="p">)</span>
</pre></div>

          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../../../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../index.html">RadIO 0.1.0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../index.html" >Module code</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2017, analysiscenter.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.5.
    </div>
  </body>
</html>